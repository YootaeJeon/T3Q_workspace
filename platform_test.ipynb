{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "outdoor-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_classification_preprocess_sub.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import logging\n",
    "\n",
    "\n",
    "def exec_process(pm):\n",
    "    logging.info('[hunmin log] the start line of the function [exec_process]')\n",
    "\n",
    "    '''\n",
    "    class PM:\n",
    "        def __init__(self):\n",
    "            self.source_path = './'\n",
    "            self.target_path = './meta_data'\n",
    "\n",
    "        pm = PM()\n",
    "        exec_process(pm)\n",
    "    '''\n",
    "\n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(pm.source_path)  \n",
    "    \n",
    "    # pm.source_path의 dataset.zip 파일을\n",
    "    # pm.target_path 경로에 압축해제\n",
    "    my_zip_path = os.path.join(pm.source_path,'dataset.zip')\n",
    "    extract_zip_file = zipfile.ZipFile(my_zip_path)  # <zipfile.ZipFile filename='./dataset.zip' mode='r'>\n",
    "    extract_zip_file.extractall(pm.target_path)\n",
    "    extract_zip_file.close()\n",
    "    \n",
    "\n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(pm.target_path)\n",
    "\n",
    "    logging.info('[hunmin log] the finish line of the function [exec_process]')\n",
    "\n",
    "\n",
    "# 저장 파일 확인\n",
    "def list_files_directories(path):\n",
    "    # Get the list of all files and directories in current working directory\n",
    "    dir_list = os.listdir(path)\n",
    "    logging.info('[hunmin log] ★ Files and directories in {} :'.format(path))\n",
    "    logging.info('[hunmin log] ★ dir_list : {}'.format(dir_list))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "structural-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_classification_preprocess.py\n",
    "\n",
    "'''\n",
    "from image_classification_preprocess_sub import exec_process\n",
    "'''\n",
    "\n",
    "import logging\n",
    "\n",
    "def process_for_train(pm):   # 데이터셋 준비(Dataset Setup) \n",
    "    exec_process(pm)      # 저장 파일 확인하기\n",
    "    logging.info('[hunmin log] the end line of the function [process_for_train]')\n",
    "    \n",
    "\n",
    "def init_svc(im, rule):     # 전처리 객체 불러오기\n",
    "    return {}\n",
    "\n",
    "\n",
    "def transform(df, params, batch_id):   #추론 데이터 전처리(Data Preprocessing)(생략 가능)\n",
    "    logging.info('[hunmin log] df.shape : {}'.format(df.shape))\n",
    "    logging.info('[hunmin log] type(df) : {}'.format(type(df)))\n",
    "    logging.info('[hunmin log] the end line of the function [transform]')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "guilty-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "import logging, os\n",
    "\"\"\"\n",
    "from train_sub import exec_train\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, \\\n",
    "                            T3QAI_TRAIN_DATA_PATH, T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    result = None\n",
    "    result_msg = \"success\"\n",
    "    tc.train_start()\n",
    "    try:\n",
    "        train()\n",
    "    except Exception as e:\n",
    "        result = e\n",
    "        result_msg = e\n",
    "        logging.info('error log : {}'.format(e))\n",
    "    tc.train_finish(result, result_msg)\n",
    "\n",
    "def train():\n",
    "    exec_train()\n",
    "    logging.info('[hunmin log] the end line of the function [train]')\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "chronic-sympathy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[stop words : default] : 재배법 수확량 수확 분야 조사 지역 특성 분석 개발 방법 으로 유형 위한 규모 연구 항목 에서 구축 자료 평가 처리 이용 재료 활용 작업 구조 지표 기준 설계 조건 유용 성분 성능 개소\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "#  train_sub.py\n",
    "\n",
    "\"\"\"\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, \\\n",
    "                            T3QAI_TRAIN_DATA_PATH, T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH\n",
    "\"\"\"\n",
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "\n",
    "# 저장 파일 확인\n",
    "def list_files_directories(path):\n",
    "    # Get the list of all files and directories in current working directory\n",
    "    dir_list = os.listdir(path)\n",
    "    logging.info('[hunmin log] Files and directories in {} :'.format(path))\n",
    "    logging.info('[hunmin log] dir_list : {}'.format(dir_list))\n",
    "\n",
    "## user algorithm \n",
    "# T3Q.ai 공통, 알고리즘 파라미터 불러오기(dictionary 형태)\n",
    "# params = tc.train_load_param()\n",
    "# logging.info('params : {}'.format(params))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus, 'GPU')\n",
    "        logging.info('[hunmin log] gpu set complete')\n",
    "        logging.info('[hunmin log] num of gpu: {}'.format(len(gpus)))\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        logging.info('[hunmin log] gpu set failed')\n",
    "        logging.info(e)\n",
    "\n",
    "# 저장 파일 확인\n",
    "def list_files_directories(path):\n",
    "    # Get the list of all files and directories in current working directory\n",
    "    dir_list = os.listdir(path)\n",
    "    logging.info('[hunmin log] Files and directories in {} :'.format(path))\n",
    "    logging.info('[hunmin log] dir_list : {}'.format(dir_list))\n",
    "\n",
    "\n",
    "#불용처리 함수\n",
    "in_person_stopwords='재배법 수확량 수확 분야 조사 지역 특성 분석 개발 방법 으로 유형 위한 규모 연구 항목 에서 구축 자료 평가 처리 이용 재료 활용 작업 구조 지표 기준 설계 조건 유용 성분 성능 개소'\n",
    "logging.info('[stop words : default] : {}'.format(in_person_stopwords)) \n",
    "\n",
    "stop_words = in_person_stopwords\n",
    "stop_words = stop_words.split(' ')\n",
    "\n",
    "# kiwi 이용한  BERTopic\n",
    "class CustomTokenizer:\n",
    "    def __init__(self, tagger):\n",
    "        self.tagger = tagger\n",
    "    def __call__(self, sent):\n",
    "        sent = sent[:1000000]\n",
    "        word_tokens = self.tagger.analyze(sent) # 형태소 출력\n",
    "        forms_list = [token.form for token in word_tokens[0][0]] # '(토큰화결과,형태, , ) > [0][0] 뽑기\n",
    "        #word_tokens = self.tagger.morphs(sent)\n",
    "        #word_tokens = self.tagger.nouns(sent)\n",
    "        #result = [word for word in word_tokens if len(word) > 1]\n",
    "        result = [word for word in forms_list if len(word) > 1]\n",
    "        final_result = remove_stopwords_from_list(result, stop_words)\n",
    "        last_result = [re_word for re_word in final_result if len(re_word) > 1]\n",
    "        return last_result\n",
    "    \n",
    "def remove_stopwords_from_list(content_list, stopwords):\n",
    "    \"\"\"Remove stopwords\"\"\"\n",
    "    filtered_list = []\n",
    "    for sentence in content_list:\n",
    "        filtered_sentence = \" \".join([word for word in sentence.split() if word not in stopwords])\n",
    "        filtered_list.append(filtered_sentence)\n",
    "    return filtered_list\n",
    "\n",
    "def exec_train():\n",
    "    logging.info('[hunmin log] the start line of the function [exec_train]')\n",
    "    logging.info('[hunmin log] T3QAI_TRAIN_DATA_PATH : {}'.format(T3QAI_TRAIN_DATA_PATH))\n",
    "    \n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(T3QAI_TRAIN_DATA_PATH)\n",
    "    my_path = os.path.join('./dataset', '') + '/'\n",
    "    \n",
    "    # 카테고리\n",
    "    dataset=['dataset'] ##335개의 문서가 한 줄로 들어간 dataset.txt\n",
    "    dataset_num = len(dataset) #1 : dataset.txt\n",
    "\n",
    "    # 경로에 있는 문서데이터(txt에 한 줄 씩 335개 있는 1개 문서)를 load하고 dataset_numpy list에 추가한다.\n",
    "    dataset_txt = []\n",
    "    for i in range (dataset_num):\n",
    "        ad = my_path + str(dataset[i]) + '.txt'\n",
    "        dataset_txt.append(ad)\n",
    "  \n",
    "    for i in range (dataset_num):\n",
    "        logging.info('[hunmin log] : {}'.format(dataset_txt[i]))\n",
    "        \n",
    "    text_file = my_path + str(dataset[i]) + '.txt'   \n",
    "\n",
    "    documents = [line.strip() for line in open(text_file, encoding=\"utf-8\").readlines()]\n",
    "    logging.info('[hunmin log] Input 산림청 첫번째 문서 확인 예시: {}'.format(documents[0]))\n",
    "\n",
    "    preprocessed_documents = []\n",
    "    logging.info('[hunmin log] 총 문서 개수: {}'.format(len(documents)))\n",
    "\n",
    "    for line in tqdm(documents):\n",
    "    # 빈 문자열이거나 숫자로만 이루어진 줄은 제외\n",
    "        if line and not line.replace(' ', '').isdecimal():\n",
    "            preprocessed_documents.append(line)\n",
    "\n",
    "    ###########################################################################\n",
    "    ## 불용어 제거 단어\n",
    "    ## in_person_stopwords = '재배법 수확량 수확 분야 조사 지역 특성 분석 개발 방법 으로 유형 위한 규모 연구 항목 에서 구축 자료 평가 처리 이용 재료 활용 작업 구조 지표 기준 설계 조건 유용 성분 성능 개소'\n",
    "    ## stop_words = in_person_stopwords\n",
    "    ## stop_words = stop_words.split(' ')\n",
    "    ## logging.info('[hunmin log]  불용어 제거 단어: {}'.format(stop_words))\n",
    "    logging.info('[hunmin log]  불용어 제거 단어: {}'.format(stop_words))\n",
    "    ###########################################################################\n",
    "\n",
    "    # 모델 구축\n",
    "    # 단일 gpu 혹은 cpu학습\n",
    "    num_classes = 1\n",
    "\n",
    "    if len(gpus) < 2:\n",
    "        model = model_build_and_compile(num_classes)\n",
    "    # multi-gpu\n",
    "    else:\n",
    "        # strategy = tf.distribute.MirroredStrategy()\n",
    "        logging.info('[humin log] gpu devices num {}'.format(strategy.num_replicas_in_sync))\n",
    "        with strategy.scope():\n",
    "            model = model_build_and_compile(num_classes)\n",
    "\n",
    "    # Create topic model\n",
    "    topics, probs = model.fit_transform(preprocessed_documents)\n",
    "\n",
    "    ###########################################################################\n",
    "    ## 플랫폼 시각화\n",
    "    ###########################################################################\n",
    "\n",
    "    # #모델 저장하기\n",
    "    # logging.info('[hunmin log] T3QAI_BERTopic_MODEL_PATH : {}'.format(T3QAI_TRAIN_MODEL_PATH))\n",
    "    # custom_model_name= 'bertopic_model' # params['model_name'])\n",
    "    # logging.info('[custaom_model_name log] : {}'.format(custom_model_name))\n",
    "    # model.save(os.path.join(T3QAI_TRAIN_MODEL_PATH, custom_model_name),serialization=\"safetensors\", save_embedding_model=embedding_model)\n",
    "   \n",
    "    # 저장 파일 확인\n",
    "    logging.info('[hunmin log] ★모델저장 완료★')\n",
    "    list_files_directories(T3QAI_TRAIN_DATA_PATH)\n",
    "\n",
    "    logging.info('[hunmin log] the finish line of the function [exec_train]')\n",
    "\n",
    "    # 모델 토픽 결과 출력\n",
    "    topics: List[int] = None\n",
    "    top_n_topics: int = None\n",
    "\n",
    "    # 전체 주제 수 출력하기\n",
    "    freq_df = model.get_topic_freq()\n",
    "    freq_df = freq_df.loc[freq_df.Topic != -1, :]\n",
    "\n",
    "    if topics is not None:\n",
    "        topics = list(topics)\n",
    "    elif top_n_topics is not None:\n",
    "        topics = sorted(freq_df.Topic.to_list()[:top_n_topics])\n",
    "    else:\n",
    "        topics = sorted(freq_df.Topic.to_list()[0:])\n",
    "\n",
    "    logging.info('[★ 주제 수 ] : {} 개로 예상합니다.'.format(len(topics)))\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Result topic 결과입니다.')\n",
    "    model_get_topic_info(model)\n",
    "    \n",
    "    #model_visualize_barchart(model)\n",
    "    #visualize_topics2(model)\n",
    "\n",
    "    # Show wordcloud\n",
    "    # create_wordcloud(model, topic=1)\n",
    "    filepath1 = os.path.join(T3QAI_TRAIN_OUTPUT_PATH, \"heatmap.html\")\n",
    "    filepath2 = os.path.join(T3QAI_TRAIN_OUTPUT_PATH, \"visualize_barchart.html\")\n",
    "    \n",
    "    fig = model.visualize_heatmap()\n",
    "    fig.write_html(filepath1)\n",
    "    \n",
    "    fig = model.visualize_barchart()\n",
    "    fig.write_html(filepath2)\n",
    "    \n",
    "    ###################################################################################################################    \n",
    "    #  def visualize_documents2(docs)\n",
    "    ###################################################################################################################\n",
    "    from typing import List\n",
    "    from typing import Union\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    def visualize_documents2(topic_model,\n",
    "                        docs: List[str],\n",
    "                        topics: List[int] = None,\n",
    "                        embeddings: np.ndarray = None,\n",
    "                        reduced_embeddings: np.ndarray = None,\n",
    "                        sample: float = None,\n",
    "                        hide_annotations: bool = False,\n",
    "                        hide_document_hover: bool = False,\n",
    "                        custom_labels: Union[bool, str] = False,\n",
    "                        title: str = \"<b>Documents and Topics</b>\",\n",
    "                        width: int = 1200,\n",
    "                        height: int = 750):\n",
    "\n",
    "\n",
    "        # topic_per_doc = model.topics_\n",
    "\n",
    "        doc_info = model.get_document_info(docs)\n",
    "        topic_per_doc = doc_info['Topic']\n",
    "\n",
    "        # Sample the data to optimize for visualization and dimensionality reduction\n",
    "        if sample is None or sample > 1:\n",
    "            sample = 1\n",
    "\n",
    "        indices = []\n",
    "\n",
    "        for topic in set(topic_per_doc):\n",
    "            s = np.where(np.array(topic_per_doc) == topic)[0]        # np.where 조건을 만족하는 값 찾기\n",
    "            size = len(s) if len(s) < 100 else int(len(s) * sample)\n",
    "            np.random.seed(42)\n",
    "            indices.extend(np.random.choice(s, size=size, replace=False))    # 랜덤으로 선택, 결과 값 달라지기 때문에 umap에서 42고정\n",
    "        indices = np.array(indices)\n",
    "\n",
    "        print('indices :' , indices)\n",
    "\n",
    "        #print('len(indices)', len(indices))\n",
    "\n",
    "        df = pd.DataFrame({\"topic\": np.array(topic_per_doc)[indices]})\n",
    "        #df[\"doc_psg\"] = [docs[index] for index in indices]\n",
    "        df[\"topic\"] = [topic_per_doc[index] for index in indices]\n",
    "        df[\"doc\"] = [f\"문서번호 : {i}_\" + \"\".join(docs[i][0:20]) for i in indices]\n",
    "\n",
    "\n",
    "        # Extract embeddings if not already done\n",
    "        if sample is None:\n",
    "            if embeddings is None and reduced_embeddings is None:\n",
    "                embeddings_to_reduce = model._extract_embeddings(df.doc.to_list(), method=\"document\")\n",
    "            else:\n",
    "                embeddings_to_reduce = embeddings\n",
    "        else:\n",
    "            if embeddings is not None:\n",
    "                embeddings_to_reduce = embeddings[indices]\n",
    "            elif embeddings is None and reduced_embeddings is None:\n",
    "                embeddings_to_reduce = model._extract_embeddings(df.doc.to_list(), method=\"document\")\n",
    "\n",
    "        print('차원 감소 임베딩:', reduced_embeddings)\n",
    "\n",
    "        # Reduce input embeddings\n",
    "        if reduced_embeddings is None:\n",
    "            umap_model = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine',random_state=42).fit(embeddings_to_reduce)\n",
    "            embeddings_2d = umap_model.embedding_\n",
    "        elif sample is not None and reduced_embeddings is not None:\n",
    "            embeddings_2d = reduced_embeddings[indices]\n",
    "        elif sample is None and reduced_embeddings is not None:\n",
    "            embeddings_2d = reduced_embeddings\n",
    "\n",
    "        print(embeddings_2d)\n",
    "\n",
    "        unique_topics = set(topic_per_doc)\n",
    "        if topics is None:\n",
    "            topics = unique_topics\n",
    "\n",
    "        # Combine data\n",
    "        df[\"x\"] = embeddings_2d[:, 0]\n",
    "        df[\"y\"] = embeddings_2d[:, 1]\n",
    "\n",
    "        # Prepare text and names 주제 이름 넣어주기\n",
    "        if isinstance(custom_labels, str):\n",
    "            names = [[[str(topic), None]] + model.topic_aspects_[custom_labels][topic] for topic in unique_topics]\n",
    "            names = [\"_\".join([label[0] for label in labels[:4]]) for labels in names]\n",
    "            names = [label if len(label) < 30 else label[:27] + \"...\" for label in names]\n",
    "        elif model.custom_labels_ is not None and custom_labels:\n",
    "            names = [model.custom_labels_[topic + model._outliers] for topic in unique_topics]\n",
    "        else:\n",
    "            names = [f\"{topic}_\" + \"_\".join([word for word, value in model.get_topic(topic)][:3]) for topic in unique_topics]\n",
    "    \n",
    "        # Visualize\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Outliers and non-selected topics\n",
    "        non_selected_topics = set(unique_topics).difference(topics)\n",
    "\n",
    "        if len(non_selected_topics) == 0:\n",
    "            non_selected_topics = [-1]\n",
    "\n",
    "        selection = df.loc[df.topic.isin(non_selected_topics), :]\n",
    "        selection[\"text\"] = \"\"\n",
    "        selection.loc[len(selection), :] = [None, None, selection.x.mean(), selection.y.mean(), \"Other documents\"]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scattergl(\n",
    "                x=selection.x,\n",
    "                y=selection.y,\n",
    "                hovertext=selection.doc if not hide_document_hover else None,\n",
    "                hoverinfo=\"text\",\n",
    "                mode='markers+text',\n",
    "                name=\"other\",\n",
    "                showlegend=False,\n",
    "                marker=dict(color='#CFD8DC', size=5, opacity=0.5)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Selected topics\n",
    "        for name, topic in zip(names, unique_topics): # 0_산림_목재_참나무, 0 \n",
    "            print(topic)\n",
    "            if topic in topics and topic != -1:\n",
    "                selection = df.loc[df.topic == topic, :]\n",
    "                print(selection)\n",
    "                selection[\"text\"] = \"\"\n",
    "\n",
    "                if not hide_annotations:\n",
    "                    selection.loc[len(selection), :] = [None, None, selection.x.mean(), selection.y.mean(), name]\n",
    "\n",
    "                fig.add_trace(\n",
    "                    go.Scattergl(\n",
    "                        x=selection.x,\n",
    "                        y=selection.y,\n",
    "                        hovertext=selection.doc if not hide_document_hover else None,\n",
    "                        hoverinfo=\"text\",\n",
    "                        text=selection.text,\n",
    "                        mode='markers+text',\n",
    "                        name=name,\n",
    "                        textfont=dict(\n",
    "                            size=12,\n",
    "                        ),\n",
    "                        marker=dict(size=5, opacity=0.5)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # Add grid in a 'plus' shape\n",
    "        x_range = (df.x.min() - abs((df.x.min()) * .15), df.x.max() + abs((df.x.max()) * .15))\n",
    "        y_range = (df.y.min() - abs((df.y.min()) * .15), df.y.max() + abs((df.y.max()) * .15))\n",
    "        fig.add_shape(type=\"line\",\n",
    "                    x0=sum(x_range) / 2, y0=y_range[0], x1=sum(x_range) / 2, y1=y_range[1],\n",
    "                    line=dict(color=\"#CFD8DC\", width=2))\n",
    "        fig.add_shape(type=\"line\",\n",
    "                    x0=x_range[0], y0=sum(y_range) / 2, x1=x_range[1], y1=sum(y_range) / 2,\n",
    "                    line=dict(color=\"#9E9E9E\", width=2))\n",
    "        fig.add_annotation(x=x_range[0], y=sum(y_range) / 2, text=\"D1\", showarrow=False, yshift=10)\n",
    "        fig.add_annotation(y=y_range[1], x=sum(x_range) / 2, text=\"D2\", showarrow=False, xshift=10)\n",
    "\n",
    "        # Stylize layout\n",
    "        fig.update_layout(\n",
    "            template=\"simple_white\",\n",
    "            title={\n",
    "                'text': f\"{title}\",\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top',\n",
    "                'font': dict(\n",
    "                    size=22,\n",
    "                    color=\"Black\")\n",
    "            },\n",
    "            width=width,\n",
    "            height=height\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(visible=False)\n",
    "        fig.update_yaxes(visible=False)\n",
    "\n",
    "        return fig\n",
    "    \n",
    "    filepath3 = os.path.join(T3QAI_TRAIN_OUTPUT_PATH, \"visualize_document.html\")\n",
    "    fig = visualize_documents2(model, preprocessed_documents)\n",
    "    fig.write_html(filepath3)\n",
    "\n",
    "###########################################################################\n",
    "## exec_train() 호출 함수 끝\n",
    "###########################################################################\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#custom_tokenizer = CustomTokenizer(Mecab(dicpath=r'C:\\mecab\\mecab-ko-dic'))\n",
    "custom_tokenizer = CustomTokenizer(Kiwi())\n",
    "\n",
    "vectorizer = CountVectorizer( tokenizer=custom_tokenizer, max_features=3000,  ngram_range=(1, 1))\n",
    "\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "# ## user algorithm \n",
    "# # T3Q.ai 공통, 알고리즘 파라미터 불러오기(dictionary 형태)\n",
    "# params = tc.train_load_param()\n",
    "# logging.info('params : {}'.format(params))\n",
    "\n",
    "n_neighbors = 10\n",
    "n_components = 5\n",
    "min_dist = 0.2\n",
    "random_seed = 42\n",
    "min_cluster_size = 2\n",
    "\n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=n_neighbors, n_components=n_components, min_dist=min_dist, metric='cosine',random_state=random_seed)\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = vectorizer\n",
    "#CountVectorizer(tokenizer=custom_tokenizer, max_features=3000,  ngram_range=(1, 1))\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# Step 6 - (Optional) Fine-tune topic representations with \n",
    "# a `bertopic.representation` model\n",
    "representation_model = KeyBERTInspired()\n",
    "\n",
    "def model_build_and_compile(num_classes):\n",
    "    #모델 구축\n",
    "    # All steps together\n",
    "    \n",
    "    # 사용자로부터 입력 받기\n",
    "    user_input = 'auto'\n",
    "    nr_topics_input = 'auto'\n",
    "    # # 입력 값이 숫자인지 문자열인지 확인\n",
    "    # if user_input.isdigit():\n",
    "    #     # 입력 값이 숫자일 경우 실행할 코드\n",
    "    #     nr_topics_input = int(params.get('n_topics', '10')) # params['n_topics'])\n",
    "    # else:\n",
    "    #     # 입력 값이 문자열일 경우 실행할 코드\n",
    "    #     nr_topics_input = str(params.get('n_topics', 'auto')) # params['n_topics'])\n",
    "    \n",
    "    \n",
    "    logging.info('[n_topics] : {} '.format(nr_topics_input))\n",
    "    # top_n_words_input = int(params.get('top_n_words', '10')) # params['top_n_words'])\n",
    "    top_n_words_input = 10\n",
    "    logging.info('[top_n_words] : {} '.format(top_n_words_input))\n",
    "    \n",
    "    model = BERTopic(\n",
    "    nr_topics=nr_topics_input,\n",
    "    top_n_words=top_n_words_input,\n",
    "    embedding_model=embedding_model,          # Step 1 - Extract embeddings\n",
    "    umap_model=umap_model,                    # Step 2 - Reduce dimensionality\n",
    "    hdbscan_model=hdbscan_model,              # Step 3 - Cluster reduced embeddings\n",
    "    vectorizer_model=vectorizer_model,        # Step 4 - Tokenize topics\n",
    "    ctfidf_model=ctfidf_model,                # Step 5 - Extract topic words\n",
    "    representation_model=representation_model, # Step 6 - (Optional) Fine-tune topic represenations\n",
    "    calculate_probabilities=True              # 문서당 할당된 주제의 확률 대신 문서당 모든 주제의 확률을 계산합니다. 문서가 많은 경우(> 100_000) 주제 추출 속도가 느려질 수 있습니다. \n",
    "                                                # 참고: false인 경우 해당 시각화 방법을 사용할 수 없습니다 visualize_probabilities. \n",
    "                                                # 참고: 이는 HDBSCAN에 사용된 주제 확률의 근사치이며 정확한 표현은 아닙니다.\n",
    "    )\n",
    "\n",
    "    return model\n",
    "    \n",
    "#######################\n",
    "## 시각화 구현\n",
    "#######################\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 토픽 정보 출력 함수\n",
    "def model_get_topic_info(model):\n",
    "    logging.info('[★ Result topic 결과 준비가 완료되었습니다.]')\n",
    "    print(model.get_topic_info())\n",
    "    print(model.get_topic_info()['Count'])\n",
    "    print(model.get_topic_info()['Name'])\n",
    "    print(model.get_topic_info()['Representation'])\n",
    "    print(model.get_topic_info()['Representative_Docs'])\n",
    "    \n",
    "\n",
    "# BERTopic barchart 결과화면\n",
    "def model_visualize_barchart(model):\n",
    "    model.visualize_barchart(top_n_topics=50, n_words=5, custom_labels=model.set_topic_labels)\n",
    "\n",
    "#워드 클라우드 시각화 함수\n",
    "def create_wordcloud(model, topic):\n",
    "    text = {word: value for word, value in model.get_topic(topic)}\n",
    "    logging.info('[★ Word Cloud 시각화 결과 화면 준비가 완료되었습니다.]')\n",
    "    print(text)\n",
    "    FONT_PATH =r\"malgun.ttf\"\n",
    "    \n",
    "    wc = WordCloud(font_path=FONT_PATH,background_color=\"white\", max_words=1000)\n",
    "    wc.generate_from_frequencies(text)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    " \n",
    "    filepath = os.path.join(T3QAI_TRAIN_OUTPUT_PATH, 'wordcloud.jpg')\n",
    "    plt.savefig(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "alike-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_service.py\n",
    "\n",
    "\"\"\"\n",
    "from inference_service_sub import exec_init_model, exec_inference_dataframe, exec_inference_file\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "def init_model():\n",
    "    params = exec_init_model()\n",
    "    logging.info('[hunmin log] the end line of the function [init_model]')\n",
    "    return { **params }\n",
    "\n",
    "\n",
    "def inference_dataframe(df, model_info_dict):\n",
    "    result = exec_inference_dataframe(df, model_info_dict)\n",
    "    logging.info('[hunmin log] the end line of the function [inference_dataframe]')\n",
    "    return { **result }\n",
    "\n",
    "\n",
    "def inference_file(files, model_info_dict):\n",
    "    result = exec_inference_file(files, model_info_dict)\n",
    "    logging.info('[hunmin log] the end line of the function [inference_file]')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "contained-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_service_sub.py\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import logging\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from bertopic import BERTopic\n",
    "from PIL import Image\n",
    "\n",
    "\"\"\"\n",
    "from t3qai_client import DownloadFile\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, T3QAI_TRAIN_DATA_PATH, \\\n",
    "                            T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH, T3QAI_INIT_MODEL_PATH\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def exec_init_model():\n",
    "    model_path = os.path.join(T3QAI_INIT_MODEL_PATH, 'bertopic_model')\n",
    "    model = BERTopic.load(model_path)\n",
    "    model_info_dict = {\n",
    "        \"model\": model\n",
    "    }\n",
    "    return model_info_dict\n",
    "\n",
    "def exec_inference_dataframe(df, model_info_dict):\n",
    "    \n",
    "    logging.info('[hunmin log] the start line of the function [exec_inference_dataframe]')\n",
    "    \n",
    "    ## 학습 모델 준비\n",
    "    model = model_info_dict['model'] \n",
    "\n",
    "    # input 데이터 값 (전처리 된 것이 들어감)\n",
    "    new_doc = df.iloc[0,0]\n",
    "    # >>> 'model': <bertopic._bertopic.BERTopic object at 0x000001B7E93F8B48>}\n",
    "    \n",
    "    # 문서 preprocess 단계 >>> v0.2단계 생략 - 결과만 우선 테스트 중\n",
    "    print(new_doc)\n",
    "\n",
    "    # Topic transform & predict\n",
    "    topics, probs = model.transform([new_doc])\n",
    "    #print('예측한 토픽 번호 :', topics)\n",
    "\n",
    "    result = {'inference' : topics}\n",
    "    logging.info('[hunmin log] 주제 예측 결과 >> result : {}'.format(result))\n",
    "\n",
    "    return result\n",
    "\n",
    "def exec_inference_file(files, model_info_dict):\n",
    "    \n",
    "    \"\"\"파일기반 추론함수는 files와 로드한 model을 전달받습니다.\"\"\"\n",
    "    logging.info('[hunmin log] the start line of the function [exec_inference_file]')\n",
    "    model = model_info_dict['model']\n",
    " \n",
    "    inference_result = []\n",
    "    \n",
    "    for one_file in files:\n",
    "        logging.info(f'[hunmin log] inference: {one_file.filename}')\n",
    "        inference_file = one_file.file\n",
    "        new_doc = inference_file\n",
    "\n",
    "        logging.info(f'[hunmin log] predict: {one_file.filename}')\n",
    "\n",
    "        # data predict\n",
    "        # Topic transform & predict\n",
    "        topics, probs = model.transform([new_doc])\n",
    "        #print('예측한 토픽 번호 :', topics)\n",
    "        \n",
    "        inference_result.append(topics)\n",
    "        \n",
    "#     result = [DownloadFile(file_path=T3QAI_TRAIN_OUTPUT_PATH + '/Accuracy_Loss.png', file_name='result.jpg'), \n",
    "#               DownloadFile(file_path=T3QAI_TRAIN_OUTPUT_PATH + '/Accuracy_Loss.png', file_name='result2.jpg')]\n",
    "\n",
    "    result = {'inference' : inference_result}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "drawn-original",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T3QAI_TRAIN_OUTPUT_PATH: ./meta_data\n",
      "T3QAI_TRAIN_MODEL_PATH: ./meta_data\n",
      "T3QAI_TRAIN_DATA_PATH: ./meta_data\n",
      "T3QAI_TEST_DATA_PATH: ./meta_data\n",
      "T3QAI_MODULE_PATH: ./meta_data\n",
      "T3QAI_INIT_MODEL_PATH: ./meta_data\n",
      "df:                                                     0\n",
      "0  차량용 목조교량 현장 모니터링 연구 국립미천골휴양림교 저탄소사회 구축을 목재이용도 ...\n",
      "df.dtypes: 0    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import base64\n",
    "import pandas as pd\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import FileUpload\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# t3qai_client 클래스: t3qai_client 객체\n",
    "class t3qai_client:\n",
    "    def train_start(self):\n",
    "        return None\n",
    "\n",
    "    def train_finish(self, result, result_msg):\n",
    "        if result_msg != \"success\":\n",
    "            raise Exception(result_msg)\n",
    "        else:\n",
    "            logging.info('Error 확인 : {}'.format(result))\n",
    "            logging.info(\"train finish\")\n",
    "\n",
    "    def train_load_param(self):\n",
    "        '''set_param'''\n",
    "        epoch = 5\n",
    "        batch_size = 16\n",
    "        params = {\"epoch\" : epoch, 'batch_size' : batch_size}\n",
    "        return { **params }\n",
    "    \n",
    "\n",
    "\n",
    "class PM:\n",
    "    def __init__(self):\n",
    "        self.source_path = './'\n",
    "        self.target_path = './meta_data'\n",
    "        \n",
    "class UploadFile:\n",
    "    def __init__(self, file, filename):\n",
    "        self.file = file\n",
    "        self.filename = filename\n",
    "\n",
    "def DownloadFile(file_name, file_obj = None, file_path = None):\n",
    "    file_route = './meta_data/DownloadFiles'\n",
    "    os.makedirs(file_route, exist_ok = True)\n",
    "    file_dir = os.path.join(file_route, file_name)\n",
    "    if (file_obj == None) == (file_path == None):\n",
    "        Err_msg = \"[DownloadFile Error]: Only one of the 'file_path' or 'file_obj' arguments is required.\"\n",
    "        Err_msg += f\"{0 if file_obj==None else 2} arguments entered.\"\n",
    "        raise Exception(Err_msg)\n",
    "    elif(file_obj != None):\n",
    "        file_obj.seek(0)\n",
    "        file_read = base64.b64encode(file_obj.read()).decode('utf-8')\n",
    "        binary_file = base64.b64decode(file_read)\n",
    "        with open(file_dir, 'wb') as f:\n",
    "            f.write(binary_file)\n",
    "    elif(file_path != None):\n",
    "        shutil.copyfile(file_path, file_dir)\n",
    "        \n",
    "    return FileLink(file_dir)\n",
    "\n",
    "pm = PM()\n",
    "\n",
    "T3QAI_TRAIN_OUTPUT_PATH = './meta_data'\n",
    "T3QAI_TRAIN_MODEL_PATH = './meta_data'\n",
    "T3QAI_TRAIN_DATA_PATH = './meta_data'\n",
    "T3QAI_TEST_DATA_PATH = './meta_data'\n",
    "T3QAI_MODULE_PATH = './meta_data'\n",
    "T3QAI_INIT_MODEL_PATH = './meta_data'\n",
    "\n",
    "\n",
    "# t3qai_client 객체\n",
    "tc = t3qai_client()\n",
    "print('T3QAI_TRAIN_OUTPUT_PATH:', T3QAI_TRAIN_OUTPUT_PATH)\n",
    "print('T3QAI_TRAIN_MODEL_PATH:', T3QAI_TRAIN_MODEL_PATH)\n",
    "print('T3QAI_TRAIN_DATA_PATH:', T3QAI_TRAIN_DATA_PATH)\n",
    "print('T3QAI_TEST_DATA_PATH:', T3QAI_TEST_DATA_PATH)\n",
    "print('T3QAI_MODULE_PATH:', T3QAI_MODULE_PATH)\n",
    "print('T3QAI_INIT_MODEL_PATH:', T3QAI_INIT_MODEL_PATH)\n",
    "\n",
    "# init_svc(im, rule) 함수 입력\n",
    "im = None\n",
    "rule = None\n",
    "# transform(df, params, batch_id) 함수 입력\n",
    "batch_id = 0\n",
    "\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 프레임 넣기 - 문서 첫 번째 라인.txt\n",
    "data = [['차량용 목조교량 현장 모니터링 연구 국립미천골휴양림교 저탄소사회 구축을 목재이용도 증진 재질 정보 목구조시스템 구축 목조교량 모니터링 집성재 응력적층상판 도로교설계기준 Wood Bridge Monitoring Glulam Stress laminated deck Design code of highway bridge 주요 국산 침엽수재의 고부가가치 이용도 증진 저탄소 사회 구축을 위하여 국내 최초로 설계시공된 차량용 목조교량국립미천골휴양림교의 현장성능 모니터링을 통해 교량의 안전성 확보 장기 내구성 분석을 자료 구축 주변 환경 변화에 따른 교량 형상반응 계측 가교량 형상반응 원인 분석을 위해 트러스상현재 아래및 상판가로보 옆개소에서 온습도 변화를 계측함 산간지방에 위치하여 일교차 이에 따른 상대습도의 변화가 컸으며 계곡에 위치한 지리적 특성으로 인해 습도가 대체적으로 높게 나타남 교량 주변의 상대습도는 월월간 월월간 로 변화함에 따라 교량 부재의 성능과 형태의 변화가 있을 수 있음 나교량 받침의 상하 플레이트 간 상대변위 계측을 통해 교축방향 수평변형을 측정함 측정된 수평변형은 mm 내외로 매우 작았으며 교량 받침 신축 이음 부대설비의 안정적인 기능발현을 확인함 다트러스 하현재 가로보개소를 기준으로 하여 지상 LiDar 촬영 사진촬영 수준측량의 방법을 통해 교량의 처짐량인 수직변형을 계측함 수준측량법에 의해 유효한 결과를 도출할 수 있었으며 부재 접합부 손상에 의한 교량의 이상 처짐이 나타나지 않아 전반적으로 양호한 상태를 유지하고 있음을 확인함 라트러스 가로보의 중앙부 처짐량이 년보다 늘어났으나 안정화단계에 이른 것으로 판단되며 한계처짐량보다 매우 작아 구조적으로 안전함을 확인 시간 경과에 따른 트러스 부재 접합부 상태변화 모니터링 가부재 표면에서 발생할 수 있는 할렬 접착층 갈라짐 결함을 육안적으로 확인하였으며 현재까지 전반적으로 양호한 상태를 유지함 나개 트러스와 상하현재 접합부각개소에 대해 부재 사이의 접합부 간격 변화를 계측크랙측정기 적용하고 접합부 다우얼 주위의 갈라짐 발생을 조사함 크랙측정기의 부착성 문제가 있어 보완부재와 볼트연결완료하였으며 현재까지 전반적으로 양호한 상태를 유지함 다트러스 사재의 간격이 넓어지는 현상이 발견되어 구조안전성 검토와 간격의 경시적 분석을 진행하고 있음 시간 경과에 따른 응력적층상판 압체력 변화 모니터링 가응력적층상판의 압체부 개소에 로드셀을 설치하여 압체력 변화를 상시 모니터링 중에 있으며 현재까지 재압체 시점에 도달하지 않음 나환경 변화 반복적인 차량하중 재하에 의해 응력적층상판의 거동변화 해석을 위해 유한요소해석을 수행하였으며 압체력 변화 모니터링 결과와 연계하여 분석 수행 예정임 다트러스 부재에 부후가 진행되는 것으로 의심되는 치마버섯 자실체가 발생하여 정밀진단 중이며 진행되는 부후로 판단되면 방부처리 조치 계획임 라자외선 열화와 빗물피해 예방을 위해 차 도장 배수 공사 실시함 라 기술적 측면 가국산재를 이용하여 생산된 구조부재의 안정적인 구조성능 내구성 확보를 통하여 국산재의 새로운 수요 창출 고부가가치 이용 확대에 기여 나차량용 목조교량 설계기술 검증을 통한 기술력을 확보하고 나아가 국내 도로교설계기준국토해양부 재정에 목조교량의 반영 추진 가TRM 중점분야인 저탄소사회 구축을 목재이용도 증진 중 핵심기술분야로서 재질 정보 목구조시스템 구축 연구를 수행 나연구영역 목구조시스템 연구의 요소기술인 하이브리드 목구조시스템 연구와 관련하여 차량용 목조교량 구조시스템의 구조안정성 내구성 향상에 기여 주변 환경 변화 차량통행량에 따른 교량 형상반응 계측 가공시재료 국립미천골휴양림교교장 m 교폭 m의 차선 등교 나조사항목 교대 받침 수평변형 계측트러스 가로보 수직변형 계측및 방법처리방법 다시험규모 수평변형 개소 + 수직변형 개소시기 라분석항목 계절적인 환경 변화 차량통행량에 따른 목조교량의 수직수평변형 분석 시간 경과에 따른 트러스 부재 접합부 상태변화 모니터링 가공시재료 목조교량 아치 트러스길이 m 높이 m 개 나조사항목 트러스 부재리기다소나무 집성재할렬 표면결함 모니터링트러스 접합부 형상변화 모니터링 다시험규모 트러스부재+접합부시기분기 회 라분석항목 시간 경과에 따른 부재 표면 결함 발생 진행 분석시간 경과에 따른 접합부 간격 형상변화 분석 시간 경과에 따른 응력적층상판 압체력 변화 모니터링 가공시재료 국립미천골휴양림교교장 m 교폭 m의 차선 등교 나조사항목 응력적층상판 압체력 부후 다시험규모 압체부시기분기 회 라분석항목 응력적층상판의 압체력 변화 부후징후 점검']]\n",
    "df = pd.DataFrame(data)\n",
    "print('df: ', df)\n",
    "print('df.dtypes:', df.dtypes)\n",
    "\n",
    "# inference_file 함수 추론\n",
    "files = []  # 업데이트 되는 파일 주제 저장\n",
    "\n",
    "# accept 매개변수는 '*' 모두 허용, multiple 여러 파일 동시허용, description은 버튼 바로 옆에 표시\n",
    "uploader = FileUpload(accept='*', multiple=True, description='select data', button_style='danger')\n",
    "\n",
    "def uploader_change(change):\n",
    "    uploader.button_style='success'          # danger에서 select data로 변경\n",
    "    count = len(uploader.value)              # 업로드 된 파일 개수\n",
    "    uploader._counter = count\n",
    "    files.clear()                           # files.clear(): files 리스트를 비우기\n",
    "\n",
    "    for file_num in range(count):         \n",
    "        temp_data = tempfile.TemporaryFile()\n",
    "        if ipywidgets.__version__[0] == '7':\n",
    "            temp_data.write(list(uploader.value.values())[file_num]['content'])\n",
    "            file = UploadFile(temp_data, pd.DataFrame(list(uploader.value.values())[file_num]).iloc[1,0])\n",
    "        elif int(ipywidgets.__version__[0]) > 7:\n",
    "            temp_data.write(uploader.value[file_num].content)\n",
    "            file = UploadFile(temp_data, uploader.value[file_num].name)\n",
    "        files.append(file)\n",
    "\n",
    "uploader.observe(uploader_change, 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "powerful-swing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the start line of the function [exec_process]\n",
      "INFO:root:[hunmin log] Files and directories in ./ :\n",
      "INFO:root:[hunmin log] dir_list : ['0_local_BERTopic.ipynb', '0_local_BERTopic_requirement.txt', '1_local_platform_BERTopic_test.ipynb', '2_1_1_platform_BERTopic_preprocess.py', '2_1_2_platform_BERTopic_preprocess_sub.py', '2_2_1_platform_BERTopic_train.py', '2_2_2_platform_BERTopic_train_sub.py', '2_2_3_platform_BERTopic_inference_service.py', '2_2_4_platform_BERTopic_inference_service_sub.py', 'dataset', 'dataset 원본.zip', 'dataset.zip', 'LICENSE.txt', 'meta_data', 'platform_test.ipynb', 'README.txt', 'T3Q.ai_platform_image_BERTopic', 'test_dataset', 'test_dataset -원본.zip', 'test_dataset.zip']\n",
      "INFO:root:[hunmin log] Files and directories in ./meta_data :\n",
      "INFO:root:[hunmin log] dir_list : ['bertopic_model', 'dataset', 'DownloadFiles', 'heatmap.html', 'test_dataset', 'visualize_barchart.html']\n",
      "INFO:root:[hunmin log] the finish line of the function [exec_process]\n",
      "INFO:root:[hunmin log] the end line of the function [process_for_train]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "process_for_train(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "assigned-david",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the start line of the function [exec_train]\n",
      "INFO:root:[hunmin log] T3QAI_TRAIN_DATA_PATH : ./meta_data\n",
      "INFO:root:[hunmin log] Files and directories in ./meta_data :\n",
      "INFO:root:[hunmin log] dir_list : ['bertopic_model', 'dataset', 'DownloadFiles', 'heatmap.html', 'test_dataset', 'visualize_barchart.html']\n",
      "INFO:root:[hunmin log] : ./dataset\\/dataset.txt\n",
      "INFO:root:[hunmin log] Input 산림청 첫번째 문서 확인 예시: 저비용 부산물 생산체계의 공정별 요소기술개발 가치있는 미래 산림자원 육성 효율적인 수확시스템 구축 목재수확시스템 반송기 벌채부산물 생산성 임업기계 timber harvesting system Carriage logging residue productivity forestry machines 부산물 생산작업 생력화에 필요한 효과적인 목재수확계획 기법과 공정별 요소기술개발 해당사항 없음 라 기술적 측면 가 효과적인 목질원료 생산체계 구축으로 생산성 향상 실현 나 용도별 목질원료 공급으로 원료확보 경쟁 완화 시장 안정화 다 목질원료 생산관련 임업기계장비의 활성화로 관련 업체의 산업화 가 집재장비의 성능개선으로 목재생산성 향상 비용절감 실현 나 벌채부산물의 효율적인 생산공급 체계 구축 저비용 부산물 생산체계의 공정별 요소기술 가 집재작업 생산성 향상을 반송기 공시재료조사대상 반송기 가 문헌 고찰 현장방문을 통한 집재기 반송기의 유형 분류 나 집재작업 생산성 향상을 위해 개발이 요구되는 반송기 개발계획 모델 구축 시험규모조사규모 반송기 식 가 모델 Simulation 역학분석을 통한 반송기의 적용 범위 제원 나 반송기 시제품 제작 나 기반시설 위치별 효율적인 목재수확계획 기법 공시재료조사대상 체인톱 하베스터 스윙야더 반송기 가 문헌 고찰 현장방문을 통한 현행 목재수확계획 현황 문제점 파악 나 목재수확계획 개발을 대상지 지형 지리 임상특성 임도 현장 조사분석 시험규모조사규모 목재수확계획 기법 식 가 저비용 부산물 생산을 기반시설 위치별 목재수확계획 기법 나 개발된 목재수확계획 기법의 현장 적용 타당성 검토\n",
      "INFO:root:[hunmin log] 총 문서 개수: 335\n",
      "100%|██████████| 335/335 [00:00<00:00, 47557.69it/s]\n",
      "INFO:root:[hunmin log]  불용어 제거 단어: ['재배법', '수확량', '수확', '분야', '조사', '지역', '특성', '분석', '개발', '방법', '으로', '유형', '위한', '규모', '연구', '항목', '에서', '구축', '자료', '평가', '처리', '이용', '재료', '활용', '작업', '구조', '지표', '기준', '설계', '조건', '유용', '성분', '성능', '개소']\n",
      "INFO:root:[n_topics] : auto \n",
      "INFO:root:[top_n_words] : 10 \n",
      "INFO:root:[hunmin log] ★모델저장 완료★\n",
      "INFO:root:[hunmin log] Files and directories in ./meta_data :\n",
      "INFO:root:[hunmin log] dir_list : ['bertopic_model', 'dataset', 'DownloadFiles', 'heatmap.html', 'test_dataset', 'visualize_barchart.html']\n",
      "INFO:root:[hunmin log] the finish line of the function [exec_train]\n",
      "INFO:root:[★ 주제 수 ] : 20 개로 예상합니다.\n",
      "INFO:root:[★ Result topic 결과 준비가 완료되었습니다.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Result topic 결과입니다.\n",
      "    Topic  Count                            Name  \\\n",
      "0      -1     26              -1_낙엽송_산림_갈매나무과_나무   \n",
      "1       0    212                 0_산림_낙엽송_목재_소나무   \n",
      "2       1     11                  1_목재_소나무_건축_목조   \n",
      "3       2     11      2_나노셀룰로오스_나노셀룰_나노셀룰로오스의_생체   \n",
      "4       3      6                3_재배지_재배_침엽수림_뿌리   \n",
      "5       4      6                4_생합성_광합성_바이오_생체   \n",
      "6       5      6               5_oil_활성라디칼_정유_향료   \n",
      "7       6      6            6_인도네시아_바이오매스_습지_바이오   \n",
      "8       7      5           7_통합_성과_evaluation_구성   \n",
      "9       8      5                  8_유통_수확기_농도_생산   \n",
      "10      9      4                   9_통합_성과_파급_협력   \n",
      "11     10      4             10_건조제_drying_건조_수분   \n",
      "12     11      4         11_synthase_바이오_생합성_유전체   \n",
      "13     12      4                  12_한국_미백_배지_경도   \n",
      "14     13      4                 13_수출국_무역_경제_수출   \n",
      "15     14      4         14_insulation_목재_주택_낙엽송   \n",
      "16     15      4              15_당화액_연료_수처리_탄화수소   \n",
      "17     16      4        16_일본잎갈나무_느티나무_리기다소나무_식재   \n",
      "18     17      4        17_대퇴골_골다공증_바이오마커_enzyme   \n",
      "19     18      3  18_재배_재배지_cultivation_mushroom   \n",
      "20     19      2                 19_효소_기능_채취_제조법   \n",
      "\n",
      "                                       Representation  \\\n",
      "0     [낙엽송, 산림, 갈매나무과, 나무, 식물, 삼나무, 목재, 소나무, 대나무, 토양]   \n",
      "1         [산림, 낙엽송, 목재, 소나무, 식재, 재배, 묘목, 활엽수, 버섯, 국내]   \n",
      "2         [목재, 소나무, 건축, 목조, 낙엽송, 접착제, 접착, 나무, 제조, 벽체]   \n",
      "3   [나노셀룰로오스, 나노셀룰, 나노셀룰로오스의, 생체, 셀룰로오스, 유기, 가나노셀룰...   \n",
      "4      [재배지, 재배, 침엽수림, 뿌리, 연근, 농가, 약초, 고로쇠나무, 토양, 환경]   \n",
      "5    [생합성, 광합성, 바이오, 생체, 남세균, 유기산, 화학, 합성, 효소, 이산화탄소]   \n",
      "6     [oil, 활성라디칼, 정유, 향료, 항산화, 호흡기, 천식, 영양, 주름, 미생물]   \n",
      "7   [인도네시아, 바이오매스, 습지, 바이오, 환경, 온실가스, 식재, 배수, 토양, ...   \n",
      "8   [통합, 성과, evaluation, 구성, sdgs, 지침, 결과, 기준선, 체계...   \n",
      "9           [유통, 수확기, 농도, 생산, 배출, 관리, 습도, 농가, 함량, 가공]   \n",
      "10          [통합, 성과, 파급, 협력, 적용, 대상국, 수원, 연안, 효과, 공시]   \n",
      "11     [건조제, drying, 건조, 수분, 응축, 낙엽송, 재목, 습도, 절감, 수종]   \n",
      "12  [synthase, 바이오, 생합성, 유전체, 효소, 배양액, 미생물, 목재부후, ...   \n",
      "13      [한국, 미백, 배지, 경도, 산딸기, 라디칼, 구상나무, 발아, 학회지, 톱밥]   \n",
      "14       [수출국, 무역, 경제, 수출, 가격, 수출입, 수입량, 보조금, 시장, 제재]   \n",
      "15  [insulation, 목재, 주택, 낙엽송, 목조, 건축, structure, 환...   \n",
      "16  [당화액, 연료, 수처리, 탄화수소, 발열, 고압, 활성탄, 부산물, 바이오매스, 발효]   \n",
      "17  [일본잎갈나무, 느티나무, 리기다소나무, 식재, 졸참나무, 잣나무, 상수리나무, p...   \n",
      "18  [대퇴골, 골다공증, 바이오마커, enzyme, 균사체, 두개골, 발굴, metab...   \n",
      "19  [재배, 재배지, cultivation, mushroom, 식재, tree, 버섯,...   \n",
      "20        [효소, 기능, 채취, 제조법, 매뉴얼, 추출물, 가공, 활성, 제작, 원료]   \n",
      "\n",
      "                                  Representative_Docs  \n",
      "0   [삼나무편백림의 임분관리를 시업체계 가치있는 미래 산림자원 육성 고부가가치 산림자원...  \n",
      "1   [남부 주요 수종의 자원화를 가치있는 미래 산림자원 육성 고부가가치 산림자원 조성 ...  \n",
      "2   [목조건축의 고층화를 내진성능 정량화 연구 최적 가공기술을 활용한 목재이용 증진 첨...  \n",
      "3   [나노셀룰로오스 이용 에너지 의공학용 첨단 신소재 연구 저탄소사회 구축을 목재이용도...  \n",
      "4   [고품질 산양삼 생산을 친환경 재배기술 산림생명자원을 이용한 임업소득 증대 산업화 ...  \n",
      "5   [갈매나무과 식물의 항염증 물질탐색 약리기전 연구 산림생명자원을 이용한 임업소득 증...  \n",
      "6   [산림식물자원 유래 향료자원 발굴 특성 연구 저탄소사회 구축을 목재이용도 증진 목질...  \n",
      "7   [인도네시아 이탄지의 목질계 바이오에너지 생산모델 자원관리 거버넌스 연구 신기후체제...  \n",
      "8   [국제 산림이슈 선도를 산림부문 SDGs 지표 평가체계 구축 신기후체제 대응 국제북...  \n",
      "9   [임산물 수확 후 품질관리 산업화 기반 연구 산림생명자원을 이용한 임업소득 증대 산...  \n",
      "10  [지역별국가별 국제산림협력 전략 연구 삶의 질 향상을 산림경영 정책 국제북한 산림협...  \n",
      "11  [국산 주요 침엽수재의 단면크기별 건조스케줄 저탄소사회 구축을 목재이용도 증진 재질...  \n",
      "12  [목재부후균에 의한 생물학적 목질성분 변환 기반 저탄소사회 구축을 목재이용도 증진 ...  \n",
      "13  [산림식물자원 유래 향료자원 발굴 특성 연구 산림생명자원을 이용한 임업소득 증대 산...  \n",
      "14  [목재류 비관세장벽 중 기술조치 영향평가 대응방안 연구 생산이용 원천기술을 활용한 ...  \n",
      "15  [목조 공동주택의 차음 내화성능 연구 생산이용 원천기술을 활용한 산업 활성화 친환경...  \n",
      "16  [목질계 바이오매스의 선택적 열화학적 반응을 이용한 고부가가치 물질 제조 저탄소사회...  \n",
      "17  [산림자원 조성 육성 실연시험지 모니터링 생산이용 원천기술 활용 산업 활성화 산림자...  \n",
      "18  [복령을 이용한 골 대사 개선 효과 탐색 산림생명자원을 이용한 임업소득 증대 산업화...  \n",
      "19  [송이 시험지 모니터링 송이 실현 재배 가치 있는 미래 산림자원 육성 단기 임산소득...  \n",
      "20  [꾸지뽕나무로부터 퇴행성 뇌기능 개선을 효능 구명 저탄소사회 구축을 목재이용도 증진...  \n",
      "0      26\n",
      "1     212\n",
      "2      11\n",
      "3      11\n",
      "4       6\n",
      "5       6\n",
      "6       6\n",
      "7       6\n",
      "8       5\n",
      "9       5\n",
      "10      4\n",
      "11      4\n",
      "12      4\n",
      "13      4\n",
      "14      4\n",
      "15      4\n",
      "16      4\n",
      "17      4\n",
      "18      4\n",
      "19      3\n",
      "20      2\n",
      "Name: Count, dtype: int64\n",
      "0                 -1_낙엽송_산림_갈매나무과_나무\n",
      "1                    0_산림_낙엽송_목재_소나무\n",
      "2                     1_목재_소나무_건축_목조\n",
      "3         2_나노셀룰로오스_나노셀룰_나노셀룰로오스의_생체\n",
      "4                   3_재배지_재배_침엽수림_뿌리\n",
      "5                   4_생합성_광합성_바이오_생체\n",
      "6                  5_oil_활성라디칼_정유_향료\n",
      "7               6_인도네시아_바이오매스_습지_바이오\n",
      "8              7_통합_성과_evaluation_구성\n",
      "9                     8_유통_수확기_농도_생산\n",
      "10                     9_통합_성과_파급_협력\n",
      "11               10_건조제_drying_건조_수분\n",
      "12           11_synthase_바이오_생합성_유전체\n",
      "13                    12_한국_미백_배지_경도\n",
      "14                   13_수출국_무역_경제_수출\n",
      "15           14_insulation_목재_주택_낙엽송\n",
      "16                15_당화액_연료_수처리_탄화수소\n",
      "17          16_일본잎갈나무_느티나무_리기다소나무_식재\n",
      "18          17_대퇴골_골다공증_바이오마커_enzyme\n",
      "19    18_재배_재배지_cultivation_mushroom\n",
      "20                   19_효소_기능_채취_제조법\n",
      "Name: Name, dtype: object\n",
      "0       [낙엽송, 산림, 갈매나무과, 나무, 식물, 삼나무, 목재, 소나무, 대나무, 토양]\n",
      "1           [산림, 낙엽송, 목재, 소나무, 식재, 재배, 묘목, 활엽수, 버섯, 국내]\n",
      "2           [목재, 소나무, 건축, 목조, 낙엽송, 접착제, 접착, 나무, 제조, 벽체]\n",
      "3     [나노셀룰로오스, 나노셀룰, 나노셀룰로오스의, 생체, 셀룰로오스, 유기, 가나노셀룰...\n",
      "4        [재배지, 재배, 침엽수림, 뿌리, 연근, 농가, 약초, 고로쇠나무, 토양, 환경]\n",
      "5      [생합성, 광합성, 바이오, 생체, 남세균, 유기산, 화학, 합성, 효소, 이산화탄소]\n",
      "6       [oil, 활성라디칼, 정유, 향료, 항산화, 호흡기, 천식, 영양, 주름, 미생물]\n",
      "7     [인도네시아, 바이오매스, 습지, 바이오, 환경, 온실가스, 식재, 배수, 토양, ...\n",
      "8     [통합, 성과, evaluation, 구성, sdgs, 지침, 결과, 기준선, 체계...\n",
      "9             [유통, 수확기, 농도, 생산, 배출, 관리, 습도, 농가, 함량, 가공]\n",
      "10            [통합, 성과, 파급, 협력, 적용, 대상국, 수원, 연안, 효과, 공시]\n",
      "11       [건조제, drying, 건조, 수분, 응축, 낙엽송, 재목, 습도, 절감, 수종]\n",
      "12    [synthase, 바이오, 생합성, 유전체, 효소, 배양액, 미생물, 목재부후, ...\n",
      "13        [한국, 미백, 배지, 경도, 산딸기, 라디칼, 구상나무, 발아, 학회지, 톱밥]\n",
      "14         [수출국, 무역, 경제, 수출, 가격, 수출입, 수입량, 보조금, 시장, 제재]\n",
      "15    [insulation, 목재, 주택, 낙엽송, 목조, 건축, structure, 환...\n",
      "16    [당화액, 연료, 수처리, 탄화수소, 발열, 고압, 활성탄, 부산물, 바이오매스, 발효]\n",
      "17    [일본잎갈나무, 느티나무, 리기다소나무, 식재, 졸참나무, 잣나무, 상수리나무, p...\n",
      "18    [대퇴골, 골다공증, 바이오마커, enzyme, 균사체, 두개골, 발굴, metab...\n",
      "19    [재배, 재배지, cultivation, mushroom, 식재, tree, 버섯,...\n",
      "20          [효소, 기능, 채취, 제조법, 매뉴얼, 추출물, 가공, 활성, 제작, 원료]\n",
      "Name: Representation, dtype: object\n",
      "0     [삼나무편백림의 임분관리를 시업체계 가치있는 미래 산림자원 육성 고부가가치 산림자원...\n",
      "1     [남부 주요 수종의 자원화를 가치있는 미래 산림자원 육성 고부가가치 산림자원 조성 ...\n",
      "2     [목조건축의 고층화를 내진성능 정량화 연구 최적 가공기술을 활용한 목재이용 증진 첨...\n",
      "3     [나노셀룰로오스 이용 에너지 의공학용 첨단 신소재 연구 저탄소사회 구축을 목재이용도...\n",
      "4     [고품질 산양삼 생산을 친환경 재배기술 산림생명자원을 이용한 임업소득 증대 산업화 ...\n",
      "5     [갈매나무과 식물의 항염증 물질탐색 약리기전 연구 산림생명자원을 이용한 임업소득 증...\n",
      "6     [산림식물자원 유래 향료자원 발굴 특성 연구 저탄소사회 구축을 목재이용도 증진 목질...\n",
      "7     [인도네시아 이탄지의 목질계 바이오에너지 생산모델 자원관리 거버넌스 연구 신기후체제...\n",
      "8     [국제 산림이슈 선도를 산림부문 SDGs 지표 평가체계 구축 신기후체제 대응 국제북...\n",
      "9     [임산물 수확 후 품질관리 산업화 기반 연구 산림생명자원을 이용한 임업소득 증대 산...\n",
      "10    [지역별국가별 국제산림협력 전략 연구 삶의 질 향상을 산림경영 정책 국제북한 산림협...\n",
      "11    [국산 주요 침엽수재의 단면크기별 건조스케줄 저탄소사회 구축을 목재이용도 증진 재질...\n",
      "12    [목재부후균에 의한 생물학적 목질성분 변환 기반 저탄소사회 구축을 목재이용도 증진 ...\n",
      "13    [산림식물자원 유래 향료자원 발굴 특성 연구 산림생명자원을 이용한 임업소득 증대 산...\n",
      "14    [목재류 비관세장벽 중 기술조치 영향평가 대응방안 연구 생산이용 원천기술을 활용한 ...\n",
      "15    [목조 공동주택의 차음 내화성능 연구 생산이용 원천기술을 활용한 산업 활성화 친환경...\n",
      "16    [목질계 바이오매스의 선택적 열화학적 반응을 이용한 고부가가치 물질 제조 저탄소사회...\n",
      "17    [산림자원 조성 육성 실연시험지 모니터링 생산이용 원천기술 활용 산업 활성화 산림자...\n",
      "18    [복령을 이용한 골 대사 개선 효과 탐색 산림생명자원을 이용한 임업소득 증대 산업화...\n",
      "19    [송이 시험지 모니터링 송이 실현 재배 가치 있는 미래 산림자원 육성 단기 임산소득...\n",
      "20    [꾸지뽕나무로부터 퇴행성 뇌기능 개선을 효능 구명 저탄소사회 구축을 목재이용도 증진...\n",
      "Name: Representative_Docs, dtype: object\n",
      "indices : [ 46 264 211 113  94 331  70 280  12 148 208 291 237 123  20 320 253  24\n",
      " 332 129 118  87 222 328 224 215  40 152  21 270 200 188 162 104 110 221\n",
      " 275 142 292 137 168 246 304 189 159 105 127 143 149  58  39 281 174  44\n",
      "  28 282 141 103 100   7 258  88 144 239 310  99 182 274  49  16  54  43\n",
      "  66 204 308 216  79 176 261 114  63 262 116 186  41 213 164 196   3 115\n",
      "  71 190 166 134 128 214  55 177  95  33 210 165  52  14 326 254   8  42\n",
      " 299 322 218   5  51 173 234 321 231 167  13  96 185 235 268   0 293 244\n",
      " 106 247  98  69 209  61 184  34 242 236 120  59 272  72 140 245  68 219\n",
      "   4 155  83 197 296 249 307  74 119  53  10 163 135 125 325 297 133  11\n",
      "  17  93 277 194  22 250 109 286 199 269 300  97  85 158  75 267 330 255\n",
      "  92  73 132  32  89 243 323 287 192  57 238 313   1  81 223 193 226 151\n",
      " 146 172 131 112 181 334  29 288 107 156  18 136 273 150 251   6 301 324\n",
      " 169  45 290 248 257 178 256 122  19 265 303  48  31 241 117 179  80 157\n",
      "  36  77 284  90 227 183 161 203 319 217 259 240  65  86 306 153 266 225\n",
      "  56 145 314 207 278 228 229 329 279  91 311 206 316 252 154 285 191 317\n",
      "  37 230  60 138  47 108  27 121  26  82 195 315 126 298 201 312 139 276\n",
      " 180 263 147 233  64 130  25 124 171 212 170 175 271 333 220 327   2  50\n",
      "  84 318  78  76 205   9 305 111 101 187  15 302  38  23 160 202  30  35\n",
      " 294 232 295 260 309 289  67 102 198 283  62]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8280d7ffd3a249a8a29ee2b5e491b1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "차원 감소 임베딩: None\n",
      "[[ 8.38991   11.79931  ]\n",
      " [12.746222  10.429168 ]\n",
      " [11.412541  10.144917 ]\n",
      " [ 5.740336  10.037787 ]\n",
      " [ 7.865338   7.7229676]\n",
      " [ 9.232457   8.936847 ]\n",
      " [11.086871  12.307781 ]\n",
      " [ 9.261339   7.1841598]\n",
      " [11.764821  11.032231 ]\n",
      " [10.815488  12.346365 ]\n",
      " [ 7.962297  10.252466 ]\n",
      " [ 8.07106   10.379875 ]\n",
      " [10.522193  12.703469 ]\n",
      " [10.883287  11.295875 ]\n",
      " [11.010291  11.523878 ]\n",
      " [ 4.1898346  9.132327 ]\n",
      " [ 5.9232     9.81907  ]\n",
      " [11.46685   11.060003 ]\n",
      " [ 9.037386   9.613567 ]\n",
      " [ 8.007433  10.311011 ]\n",
      " [ 7.046211  12.211695 ]\n",
      " [ 5.885493  10.714647 ]\n",
      " [ 4.170816   9.092423 ]\n",
      " [ 8.025678  10.358238 ]\n",
      " [10.485144  11.402495 ]\n",
      " [ 6.3985496 10.782108 ]\n",
      " [10.8737545 11.3749075]\n",
      " [ 8.565239  11.8335   ]\n",
      " [ 7.1472044 11.450905 ]\n",
      " [ 6.0467014 10.946925 ]\n",
      " [10.96516   12.031886 ]\n",
      " [12.442798  11.302525 ]\n",
      " [11.041279  12.107218 ]\n",
      " [10.368113  10.121268 ]\n",
      " [ 8.050321  10.349491 ]\n",
      " [10.478713  11.123086 ]\n",
      " [ 9.088716   7.177307 ]\n",
      " [11.97648   11.0949   ]\n",
      " [11.322404  10.085452 ]\n",
      " [ 9.200127   9.486023 ]\n",
      " [10.055154   9.167476 ]\n",
      " [ 9.193912   9.79267  ]\n",
      " [ 8.851964   7.269336 ]\n",
      " [11.93217   11.297208 ]\n",
      " [ 9.174304  11.888561 ]\n",
      " [11.624197  11.013365 ]\n",
      " [10.113837  13.5071945]\n",
      " [ 8.348807   7.7533617]\n",
      " [ 8.668076  10.060605 ]\n",
      " [ 9.451754   9.499547 ]\n",
      " [ 6.3074384  9.905964 ]\n",
      " [ 9.215694   8.853747 ]\n",
      " [12.704065  12.380907 ]\n",
      " [10.053657   9.4684725]\n",
      " [11.9274645 12.194486 ]\n",
      " [ 8.151526  10.344074 ]\n",
      " [ 8.075444  12.304078 ]\n",
      " [12.698929  12.362429 ]\n",
      " [ 9.242581   9.336174 ]\n",
      " [10.349958  13.392013 ]\n",
      " [ 6.735732  10.576813 ]\n",
      " [ 5.5743966 10.356854 ]\n",
      " [ 5.867819  11.596521 ]\n",
      " [ 7.010896  12.192403 ]\n",
      " [11.38442   10.18212  ]\n",
      " [ 4.315206   9.280913 ]\n",
      " [10.046091   8.539299 ]\n",
      " [ 8.806828   7.2936893]\n",
      " [11.829144  11.529425 ]\n",
      " [10.231479  10.994825 ]\n",
      " [ 4.677588   9.449432 ]\n",
      " [10.042176  11.0641   ]\n",
      " [ 9.28274    9.758896 ]\n",
      " [ 8.404476   7.824999 ]\n",
      " [ 6.2555404 10.044084 ]\n",
      " [ 7.809233   7.676425 ]\n",
      " [ 8.381838  12.374932 ]\n",
      " [ 7.0786076 12.248419 ]\n",
      " [10.002496   8.506954 ]\n",
      " [10.982495  12.087194 ]\n",
      " [ 7.05306   11.397091 ]\n",
      " [ 8.48694   10.187534 ]\n",
      " [ 8.444145  12.402094 ]\n",
      " [10.426713  13.305469 ]\n",
      " [11.531848  11.181376 ]\n",
      " [ 9.662114  10.239591 ]\n",
      " [10.029421   8.533615 ]\n",
      " [ 8.841416  10.137462 ]\n",
      " [ 9.951999   9.571822 ]\n",
      " [11.277787  11.009519 ]\n",
      " [12.0213175 12.220249 ]\n",
      " [10.2394    13.441738 ]\n",
      " [10.188199  13.483511 ]\n",
      " [ 4.5432158  9.721037 ]\n",
      " [10.143996  13.541515 ]\n",
      " [ 7.810398   7.6658382]\n",
      " [ 9.312696   7.1558757]\n",
      " [ 9.935183  13.54829  ]\n",
      " [ 6.557447  11.471283 ]\n",
      " [ 7.1139774 12.278647 ]\n",
      " [ 8.54343    7.6344805]\n",
      " [ 7.968744  10.327181 ]\n",
      " [12.6563015 12.34764  ]\n",
      " [10.741572  12.36515  ]\n",
      " [ 9.101536   9.641703 ]\n",
      " [11.324436  10.128678 ]\n",
      " [12.853663  10.33592  ]\n",
      " [ 6.4844513 11.607614 ]\n",
      " [10.506969  11.384361 ]\n",
      " [ 9.876027  11.201996 ]\n",
      " [ 9.241341   9.782724 ]\n",
      " [ 6.0215654 10.695788 ]\n",
      " [12.621384  12.424687 ]\n",
      " [ 6.3255863 11.089971 ]\n",
      " [10.42169   11.094076 ]\n",
      " [ 7.1449313 12.281913 ]\n",
      " [10.005226   8.514313 ]\n",
      " [10.012563   9.273588 ]\n",
      " [ 8.6702    10.7232065]\n",
      " [ 8.606769   7.565278 ]\n",
      " [ 6.408065  10.765786 ]\n",
      " [ 4.6693225  9.881799 ]\n",
      " [10.461633  11.36426  ]\n",
      " [10.588392  11.142585 ]\n",
      " [ 9.937544  12.279756 ]\n",
      " [12.641302  10.56327  ]\n",
      " [11.826928  11.206025 ]\n",
      " [ 4.1863866  9.067343 ]\n",
      " [ 4.3882513  9.335659 ]\n",
      " [ 6.294909  11.004075 ]\n",
      " [ 4.1652446  9.05759  ]\n",
      " [11.369116  10.930045 ]\n",
      " [ 8.127738  12.329228 ]\n",
      " [ 9.856674  11.130709 ]\n",
      " [12.430378  11.308162 ]\n",
      " [ 5.798738  10.064813 ]\n",
      " [10.097119  13.5436325]\n",
      " [ 5.9107485 11.544025 ]\n",
      " [ 9.177062   9.983217 ]\n",
      " [11.702576  11.014841 ]\n",
      " [11.790812  11.141015 ]\n",
      " [ 8.858892   7.268073 ]\n",
      " [ 5.5401134 10.32706  ]\n",
      " [10.050168  11.611893 ]\n",
      " [ 5.722535  10.501648 ]\n",
      " [12.4346485 11.287597 ]\n",
      " [ 9.2249     9.489904 ]\n",
      " [ 8.877345   7.2531343]\n",
      " [10.189289   9.925477 ]\n",
      " [ 5.9203835 10.883223 ]\n",
      " [ 9.874905  11.511751 ]\n",
      " [12.764537  10.414703 ]\n",
      " [ 9.305092   7.1827   ]\n",
      " [ 8.225793   7.8786254]\n",
      " [10.62311   11.986971 ]\n",
      " [ 9.204102  11.854453 ]\n",
      " [ 7.8420715  7.7033467]\n",
      " [10.1825695 13.470558 ]\n",
      " [ 8.67144   10.114489 ]\n",
      " [ 6.0594134 10.91104  ]\n",
      " [ 6.3453884 11.11652  ]\n",
      " [11.969149  12.286486 ]\n",
      " [ 5.920984  11.450199 ]\n",
      " [ 6.5219035 11.55208  ]\n",
      " [ 9.3652115 10.0282135]\n",
      " [ 6.0342975 10.988989 ]\n",
      " [ 6.46418   11.549135 ]\n",
      " [ 9.257613   7.155754 ]\n",
      " [ 8.136058   7.8951135]\n",
      " [ 4.685143   9.928178 ]\n",
      " [ 7.0338526 12.187024 ]\n",
      " [12.570588  10.655259 ]\n",
      " [ 9.239948   8.886328 ]\n",
      " [ 4.474973   9.280393 ]\n",
      " [ 8.523941  11.903012 ]\n",
      " [ 6.41941   11.5171795]\n",
      " [10.197315   9.908311 ]\n",
      " [ 9.928077  11.442912 ]\n",
      " [ 9.85199   11.219487 ]\n",
      " [10.620907  10.95932  ]\n",
      " [ 8.358705   7.813639 ]\n",
      " [11.855219  11.326629 ]\n",
      " [ 9.854016  11.1403055]\n",
      " [ 8.728103   7.4203205]\n",
      " [ 8.144898  10.482869 ]\n",
      " [ 8.763379  10.022628 ]\n",
      " [10.192463   9.873471 ]\n",
      " [ 5.857177  10.105895 ]\n",
      " [ 4.562546   9.326389 ]\n",
      " [10.040312  11.259248 ]\n",
      " [10.076688  13.016721 ]\n",
      " [ 4.6718793  9.921994 ]\n",
      " [ 9.600816  10.523772 ]\n",
      " [10.722219  12.485508 ]\n",
      " [ 8.892125  11.817554 ]\n",
      " [ 4.678456   9.927939 ]\n",
      " [ 8.067228  10.335961 ]\n",
      " [10.835004  11.34098  ]\n",
      " [10.335272  13.268223 ]\n",
      " [ 4.148896   9.06636  ]\n",
      " [ 7.0577607 12.215644 ]\n",
      " [ 5.933415  11.540167 ]\n",
      " [ 9.253159   7.16182  ]\n",
      " [11.597018  12.029225 ]\n",
      " [ 9.307178   9.509147 ]\n",
      " [11.5656185 10.49903  ]\n",
      " [ 4.242807   9.169293 ]\n",
      " [ 6.427663  10.749473 ]\n",
      " [ 9.566374   9.551367 ]\n",
      " [ 8.58905    7.580719 ]\n",
      " [ 6.4110494 10.767892 ]\n",
      " [ 4.237823   9.122229 ]\n",
      " [ 6.74176   11.404632 ]\n",
      " [12.571946  12.430975 ]\n",
      " [ 6.7699223 11.429457 ]\n",
      " [11.2049885 10.711138 ]\n",
      " [12.147333  12.210427 ]\n",
      " [12.553621  12.423892 ]\n",
      " [ 6.771912  11.396799 ]\n",
      " [11.250541  10.717453 ]\n",
      " [10.090636  12.680795 ]\n",
      " [11.34586   10.757019 ]\n",
      " [11.43481   10.867015 ]\n",
      " [ 9.416993  14.390882 ]\n",
      " [ 9.888563  13.734584 ]\n",
      " [ 9.383609  14.374298 ]\n",
      " [ 9.433265  14.452365 ]\n",
      " [ 9.416528  14.389379 ]\n",
      " [ 9.353196  14.277557 ]\n",
      " [ 9.357428  14.265502 ]\n",
      " [ 9.336022  14.214206 ]\n",
      " [ 9.297039  14.079889 ]\n",
      " [ 9.364341  14.154576 ]\n",
      " [ 9.348511  14.173518 ]\n",
      " [10.581962  11.890556 ]\n",
      " [10.594818  11.7621   ]\n",
      " [ 5.088711   9.604663 ]\n",
      " [ 5.054311   9.565619 ]\n",
      " [ 5.0677285  9.590699 ]\n",
      " [ 5.080484   9.610339 ]\n",
      " [10.625206  12.003694 ]\n",
      " [10.38038   12.095719 ]\n",
      " [10.675934  12.441317 ]\n",
      " [10.618187  11.863003 ]\n",
      " [10.517675  12.001958 ]\n",
      " [10.661224  12.15978  ]\n",
      " [ 8.924656  12.118424 ]\n",
      " [ 8.847479  12.020837 ]\n",
      " [ 9.537     11.807259 ]\n",
      " [ 8.91254   12.076928 ]\n",
      " [ 9.394364  11.8408575]\n",
      " [ 9.014689  12.039906 ]\n",
      " [ 7.7815285 10.429725 ]\n",
      " [10.027156  13.484953 ]\n",
      " [ 8.937261  10.300231 ]\n",
      " [ 9.706811  13.641841 ]\n",
      " [ 8.9624405 10.290555 ]\n",
      " [ 9.696539  13.625151 ]\n",
      " [ 4.4784684  9.265299 ]\n",
      " [ 8.755576  11.070716 ]\n",
      " [ 8.793021  11.1086035]\n",
      " [12.73952   10.436527 ]\n",
      " [ 8.804841  11.157145 ]\n",
      " [10.373784   9.449515 ]\n",
      " [10.528249  10.074054 ]\n",
      " [10.3688345  9.403025 ]\n",
      " [10.345375   9.419484 ]\n",
      " [10.357474   9.428977 ]\n",
      " [10.436809  11.221535 ]\n",
      " [12.753795  10.422937 ]\n",
      " [ 8.246314   7.8757443]\n",
      " [10.454426  11.171453 ]\n",
      " [ 5.721492  11.056202 ]\n",
      " [ 5.703226  11.07202  ]\n",
      " [ 5.7037168 11.045345 ]\n",
      " [ 5.7115974 11.045    ]\n",
      " [ 9.687949  13.676081 ]\n",
      " [ 9.854093  13.700275 ]\n",
      " [12.335975  11.74122  ]\n",
      " [ 9.821539  13.7146435]\n",
      " [ 8.905493  12.061023 ]\n",
      " [ 9.5929365 10.050663 ]\n",
      " [10.032866  10.00976  ]\n",
      " [12.5744505 10.606269 ]\n",
      " [11.429085  10.479321 ]\n",
      " [ 9.548762  11.829219 ]\n",
      " [11.482757  10.472111 ]\n",
      " [ 9.506796  10.095014 ]\n",
      " [ 9.069882  12.520668 ]\n",
      " [ 9.107044  12.575124 ]\n",
      " [ 9.106174  12.5608835]\n",
      " [ 9.120913  12.589669 ]\n",
      " [10.484652  11.724867 ]\n",
      " [10.497183  11.655217 ]\n",
      " [ 9.323522  12.374505 ]\n",
      " [10.517069  11.622504 ]\n",
      " [ 5.24268    9.999274 ]\n",
      " [ 5.3471894 10.118451 ]\n",
      " [ 5.337324  10.089471 ]\n",
      " [ 5.3105774 10.067    ]\n",
      " [12.254183  11.8631525]\n",
      " [12.134303  11.916097 ]\n",
      " [12.289146  11.840499 ]\n",
      " [12.263257  11.8531   ]\n",
      " [12.188859  11.94217  ]\n",
      " [12.193092  11.977572 ]\n",
      " [12.147004  11.9881315]\n",
      " [10.6036625 12.054116 ]\n",
      " [12.257099  11.710018 ]\n",
      " [ 9.664023  10.434056 ]\n",
      " [10.767503  11.869916 ]\n",
      " [11.026122  12.285492 ]\n",
      " [ 8.164322   7.915009 ]\n",
      " [ 9.892024  10.125318 ]\n",
      " [10.016034  11.301363 ]\n",
      " [10.12279    9.840998 ]\n",
      " [ 7.869815   7.731506 ]\n",
      " [10.0988245 12.654801 ]\n",
      " [ 6.6205826 10.846367 ]\n",
      " [10.841006  10.593065 ]\n",
      " [ 9.71027   10.416771 ]\n",
      " [ 6.4434156 11.007024 ]\n",
      " [10.114973  12.421942 ]\n",
      " [ 8.551487  11.880961 ]\n",
      " [10.131791  12.445093 ]\n",
      " [12.766102  10.406883 ]\n",
      " [11.744214  11.896188 ]\n",
      " [10.115574   9.882131 ]\n",
      " [ 6.446927  11.203394 ]\n",
      " [ 5.9502635 10.971082 ]\n",
      " [10.060739   9.519329 ]\n",
      " [ 6.7001667 10.895913 ]\n",
      " [10.879227  12.565777 ]\n",
      " [10.831209  12.626931 ]\n",
      " [10.833801  10.601024 ]]\n",
      "0\n",
      "     topic                              doc          x          y\n",
      "0        0   문서번호 : 46_건축내장용 판재의 terpene방산    8.389910  11.799310\n",
      "1        0  문서번호 : 264_목재의 연안지역 활용 방안 연구 최적  12.746222  10.429168\n",
      "2        0  문서번호 : 211_목재생산비용 절감을 기반시설 효율화   11.412541  10.144917\n",
      "3        0  문서번호 : 113_국산 활엽수재의 고부가가치 이용을 품   5.740336  10.037787\n",
      "4        0   문서번호 : 94_천연갱신을 통한 소나무낙엽송 후계림    7.865338   7.722968\n",
      "..     ...                              ...        ...        ...\n",
      "207      0  문서번호 : 156_에너지 저장용 소재 개발을 리그닌 천   6.427663  10.749473\n",
      "208      0   문서번호 : 18_목재제품의 국가표준 개선 운영체계 구   9.566374   9.551367\n",
      "209      0  문서번호 : 136_안전사고 저감을 산림작업 개선에 관한   8.589050   7.580719\n",
      "210      0  문서번호 : 273_에너지 저장용 소재 개발을 리그닌 천   6.411049  10.767892\n",
      "211      0  문서번호 : 150_숲속의 한반도 실현을 남북한 통합 산   4.237823   9.122229\n",
      "\n",
      "[212 rows x 4 columns]\n",
      "1\n",
      "     topic                              doc          x          y\n",
      "212      1  문서번호 : 251_목조주택용 구조벽 최적 목질판상재의    6.741760  11.404632\n",
      "213      1    문서번호 : 6_차량용 목조교량 현장 모니터링 연구   12.571946  12.430975\n",
      "214      1  문서번호 : 301_목조주택용 구조벽 최적 목질판상재의    6.769922  11.429457\n",
      "215      1  문서번호 : 324_목조건축의 고층화를 내진성능 정량화   11.204988  10.711138\n",
      "216      1  문서번호 : 169_차량용 목조교량 현장 모니터링 연구국  12.147333  12.210427\n",
      "217      1   문서번호 : 45_차량용 목조교량 현장 모니터링 연구   12.553621  12.423892\n",
      "218      1  문서번호 : 290_목조주택용 구조벽 최적 목질판상재의    6.771912  11.396799\n",
      "219      1  문서번호 : 248_목조건축의 고층화를 내진성능 정량화   11.250541  10.717453\n",
      "220      1  문서번호 : 257_BIM 기반 구조용 직교집성판CLT   10.090636  12.680795\n",
      "221      1  문서번호 : 178_목조건축의 고층화를 내진성능 정량화   11.345860  10.757019\n",
      "222      1  문서번호 : 256_목조건축의 고층화를 내진성능 정량화   11.434810  10.867015\n",
      "2\n",
      "     topic                              doc         x          y\n",
      "223      2  문서번호 : 122_리그닌 유도체 나노섬유를 이용한 에폭  9.416993  14.390882\n",
      "224      2   문서번호 : 19_나노셀룰로오스 복합재료의 기능성 첨단  9.888563  13.734584\n",
      "225      2  문서번호 : 265_셀룰로오스 나노섬유CNF의 다공성 구  9.383609  14.374298\n",
      "226      2  문서번호 : 303_셀룰로오스 나노섬유CNF의 다공성 구  9.433265  14.452365\n",
      "227      2   문서번호 : 48_리그닌 유도체 나노섬유를 이용한 에폭  9.416528  14.389379\n",
      "228      2   문서번호 : 31_리그닌 유도체 나노섬유를 이용한 에폭  9.353196  14.277557\n",
      "229      2  문서번호 : 241_나노셀룰로오스 이용 에너지 의공학용   9.357428  14.265502\n",
      "230      2  문서번호 : 117_나노셀룰로오스 이용 에너지 의공학용   9.336022  14.214206\n",
      "231      2  문서번호 : 179_나노셀룰로오스 이용 에너지 의공학용   9.297039  14.079889\n",
      "232      2   문서번호 : 80_나노셀룰로오스 이용 에너지 의공학용   9.364341  14.154576\n",
      "233      2  문서번호 : 157_나노셀룰로오스 이용 에너지 의공학용   9.348511  14.173518\n",
      "3\n",
      "     topic                              doc          x          y\n",
      "234      3   문서번호 : 36_주요 산채산약초 수액자원의 친환경 재  10.581962  11.890556\n",
      "235      3   문서번호 : 77_주요 산채산약초 수액자원의 친환경 재  10.594818  11.762100\n",
      "236      3  문서번호 : 284_고품질 산양삼 생산을 친환경 재배기술   5.088711   9.604663\n",
      "237      3   문서번호 : 90_고품질 산양삼 생산을 친환경 재배기술   5.054311   9.565619\n",
      "238      3  문서번호 : 227_고품질 산양삼 생산을 친환경 재배기술   5.067729   9.590699\n",
      "239      3  문서번호 : 183_고품질 산양삼 생산을 친환경 재배기술   5.080484   9.610339\n",
      "4\n",
      "     topic                              doc          x          y\n",
      "240      4  문서번호 : 161_탄소자원화를 광합성 기작 이용 목질계  10.625206  12.003694\n",
      "241      4  문서번호 : 203_탄소자원화를 광합성 기작 이용 목질계  10.380380  12.095719\n",
      "242      4  문서번호 : 319_갈매나무과 식물의 항염증 물질탐색 약  10.675934  12.441317\n",
      "243      4  문서번호 : 217_탄소자원화를 광합성 기작 이용 목질계  10.618187  11.863003\n",
      "244      4  문서번호 : 259_탄소자원화를 광합성 기작 이용 목질계  10.517675  12.001958\n",
      "245      4  문서번호 : 240_탄소자원화를 광합성 기작 이용 목질계  10.661224  12.159780\n",
      "5\n",
      "     topic                              doc         x          y\n",
      "246      5   문서번호 : 65_산림식물자원 유래 향료자원 발굴 특성  8.924656  12.118424\n",
      "247      5   문서번호 : 86_산림식물자원 유래 향료자원 발굴 특성  8.847479  12.020837\n",
      "248      5  문서번호 : 306_호흡기질환 개선용 식물정유 소재 발굴  9.537000  11.807259\n",
      "249      5  문서번호 : 153_산림식물자원 유래 향료자원 발굴 특성  8.912540  12.076928\n",
      "250      5  문서번호 : 266_호흡기질환 개선용 식물정유 소재 발굴  9.394364  11.840858\n",
      "251      5  문서번호 : 225_산림식물자원 유래 향료자원 발굴 특성  9.014689  12.039906\n",
      "6\n",
      "     topic                              doc          x          y\n",
      "252      6   문서번호 : 56_아시아 REDD+ 전략 비교 연구협력   7.781528  10.429725\n",
      "253      6  문서번호 : 145_인도네시아 이탄지의 목질계 바이오에너  10.027156  13.484953\n",
      "254      6  문서번호 : 314_인도네시아 이탄지 지역사회 발전모델    8.937261  10.300231\n",
      "255      6  문서번호 : 207_인도네시아 이탄지의 바이오에너지 기반   9.706811  13.641841\n",
      "256      6  문서번호 : 278_인도네시아 이탄지 지역사회 발전모델    8.962440  10.290555\n",
      "257      6  문서번호 : 228_인도네시아 이탄지의 바이오에너지 기반   9.696539  13.625151\n",
      "7\n",
      "     topic                              doc          x          y\n",
      "258      7  문서번호 : 229_산림부문 지속가능발전목표SDGs 국내   4.478468   9.265299\n",
      "259      7  문서번호 : 329_국제 산림이슈 선도를 산림부문 SDG   8.755576  11.070716\n",
      "260      7  문서번호 : 279_국제 산림이슈 선도를 산림부문 SDG   8.793021  11.108603\n",
      "261      7   문서번호 : 91_산림분야 공적개발원조사업의 성과증진   12.739520  10.436527\n",
      "262      7  문서번호 : 311_국제 산림이슈 선도를 산림부문 SDG   8.804841  11.157145\n",
      "8\n",
      "     topic                              doc          x          y\n",
      "263      8  문서번호 : 206_임산물 수확 후 품질관리 산업화 기반  10.373784   9.449515\n",
      "264      8  문서번호 : 316_임산물 수확후 손실경감 기술개발 실용  10.528249  10.074054\n",
      "265      8  문서번호 : 252_임산물 수확 후 품질관리 산업화 기반  10.368834   9.403025\n",
      "266      8  문서번호 : 154_임산물 수확 후 품질관리 산업화 기반  10.345375   9.419484\n",
      "267      8  문서번호 : 285_임산물 수확 후 품질관리 산업화 기반  10.357474   9.428977\n",
      "9\n",
      "     topic                              doc          x          y\n",
      "268      9  문서번호 : 191_산림부문 ODA 사업의 파급효과 분석  10.436809  11.221535\n",
      "269      9  문서번호 : 317_목재의 연안지역 활용 방안 연구 최적  12.753795  10.422937\n",
      "270      9   문서번호 : 37_지역별국가별 국제산림협력 전략 연구    8.246314   7.875744\n",
      "271      9  문서번호 : 230_산림부문 ODA 사업의 파급효과 분석  10.454426  11.171453\n",
      "10\n",
      "     topic                              doc         x          y\n",
      "272     10   문서번호 : 60_국산 주요 침엽수재의 단면크기별 건조  5.721492  11.056202\n",
      "273     10  문서번호 : 138_국산 주요 침엽수재의 단면크기별 건조  5.703226  11.072020\n",
      "274     10   문서번호 : 47_국산 주요 침엽수재의 단면크기별 건조  5.703717  11.045345\n",
      "275     10  문서번호 : 108_국산 주요 침엽수재의 단면크기별 건조  5.711597  11.045000\n",
      "11\n",
      "     topic                              doc          x          y\n",
      "276     11   문서번호 : 27_목재부후균에 의한 생물학적 목질성분    9.687949  13.676081\n",
      "277     11  문서번호 : 121_목재부후균에 의한 생물학적 성분변환    9.854093  13.700275\n",
      "278     11   문서번호 : 26_꾸지뽕나무로부터 퇴행성 뇌기능 개선을  12.335975  11.741220\n",
      "279     11   문서번호 : 82_목재부후균에 의한 생물학적 목질성분변   9.821539  13.714643\n",
      "12\n",
      "     topic                              doc          x          y\n",
      "280     12  문서번호 : 195_산림식물자원 유래 향료자원 발굴 특성   8.905493  12.061023\n",
      "281     12  문서번호 : 315_표고 톱밥배지 재배기간 단축기술 산림   9.592937  10.050663\n",
      "282     12  문서번호 : 126_자생 수실수엽류 신품종개발 이용증진기  10.032866  10.009760\n",
      "283     12  문서번호 : 298_목재문화 확산 전략 수립 연구 최적   12.574450  10.606269\n",
      "13\n",
      "     topic                              doc          x          y\n",
      "284     13  문서번호 : 201_목재류 비관세장벽 중 기술조치 영향평  11.429085  10.479321\n",
      "285     13  문서번호 : 312_WTO 지위와 FTA 변화를 고려한    9.548762  11.829219\n",
      "286     13  문서번호 : 139_목재류 비관세장벽 중 기술조치 영향평  11.482757  10.472111\n",
      "287     13  문서번호 : 276_WTO 지위와 FTA 변화를 고려한    9.506796  10.095014\n",
      "14\n",
      "     topic                              doc         x          y\n",
      "288     14  문서번호 : 180_목조 공동주택의 차음 내화성능 연구   9.069882  12.520668\n",
      "289     14  문서번호 : 263_목조 공동주택의 차음 내화성능 연구   9.107044  12.575124\n",
      "290     14  문서번호 : 147_목조 공동주택의 차음 내화성능 연구   9.106174  12.560884\n",
      "291     14  문서번호 : 233_목조 공동주택의 차음 내화성능 연구   9.120913  12.589669\n",
      "15\n",
      "     topic                              doc          x          y\n",
      "292     15   문서번호 : 64_목질계 바이오매스의 선택적 열화학적   10.484652  11.724867\n",
      "293     15  문서번호 : 130_목질계 바이오매스의 선택적 열화학적   10.497183  11.655217\n",
      "294     15   문서번호 : 25_산림바이오에너지 제조 기반 저탄소사회   9.323522  12.374505\n",
      "295     15  문서번호 : 124_목질계 바이오매스의 선택적 열화학적   10.517069  11.622504\n",
      "16\n",
      "     topic                              doc         x          y\n",
      "296     16  문서번호 : 171_산림자원 조성 육성 실연시험지 모니터  5.242680   9.999274\n",
      "297     16  문서번호 : 212_산림자원 조성 육성 실연시험지 모니터  5.347189  10.118451\n",
      "298     16  문서번호 : 170_산림자원 조성 육성 실연시험지 모니터  5.337324  10.089471\n",
      "299     16  문서번호 : 175_산림자원 조성 육성 실연시험지 모니터  5.310577  10.067000\n",
      "17\n",
      "     topic                              doc          x          y\n",
      "300     17  문서번호 : 271_복령을 이용한 골 대사 개선 효과 탐  12.254183  11.863153\n",
      "301     17  문서번호 : 333_복령을 이용한 골 대사 개선 효과 탐  12.134303  11.916097\n",
      "302     17  문서번호 : 220_복령을 이용한 골 대사 개선 효과 탐  12.289146  11.840499\n",
      "303     17  문서번호 : 327_복령을 이용한 골 대사 개선 효과 탐  12.263257  11.853100\n",
      "18\n",
      "     topic                             doc          x          y\n",
      "304     18   문서번호 : 2_송이 시험지 모니터링 송이 실현 재배  12.188859  11.942170\n",
      "305     18  문서번호 : 50_송이 시험지 모니터링 송이 실현 재배  12.193092  11.977572\n",
      "306     18  문서번호 : 84_송이 시험지 모니터링 송이 실현 재배  12.147004  11.988132\n",
      "19\n",
      "     topic                              doc          x          y\n",
      "307     19  문서번호 : 318_전통한지 제조공정 주요 한지원료 수종  10.603662  12.054116\n",
      "308     19   문서번호 : 78_꾸지뽕나무로부터 퇴행성 뇌기능 개선을  12.257099  11.710018\n",
      "-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the end line of the function [train]\n",
      "INFO:root:Error 확인 : None\n",
      "INFO:root:train finish\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# main() 함수에서 train() 함수 실행\n",
    "main()\n",
    "# 에러 발생 없을 경우 None, train finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "personal-stadium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# preprocess_sub의 transform # 데이텨 변환시 메모리에 standby 시켜놓을 데이터 반환\n",
    "params = init_svc(im, rule)\n",
    "print(params) # BERTopic 없다\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "electric-breath",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] df.shape : (1, 1)\n",
      "INFO:root:[hunmin log] type(df) : <class 'pandas.core.frame.DataFrame'>\n",
      "INFO:root:[hunmin log] the end line of the function [transform]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# preprocess_sub의 transform # 추론 이전에 데이터 변환\n",
    "df = transform(df, params, batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "tutorial-robert",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the end line of the function [init_model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': <bertopic._bertopic.BERTopic object at 0x000002864E2D78C8>}\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# inference_service의 params = exec_init_model() > dict = { 'model' : model }\n",
    "model_info_dict = init_model()\n",
    "print(model_info_dict) # { 'model' : model }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-transition",
   "metadata": {},
   "source": [
    "### CASE [추론 입력 타입 - 추론 출력 타입] : 총 4가지\n",
    "추론 입력 타입 : DataFrame &rarr; 추론 출력 타입 : Dictionary (1가지)    \n",
    "추론 입력 타입 : File &rarr; 추론 출력 타입 : Dictionary, DownloadFile, DownloadFile의 List (3가지)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-motel",
   "metadata": {},
   "source": [
    "### CASE  [DataFrame - Dictionary]\n",
    "DataFrame 입력에 대한 추론 결과를 딕셔너리(Dictionary) 형태로 리턴(return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "guilty-membrane",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the start line of the function [exec_inference_dataframe]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "차량용 목조교량 현장 모니터링 연구 국립미천골휴양림교 저탄소사회 구축을 목재이용도 증진 재질 정보 목구조시스템 구축 목조교량 모니터링 집성재 응력적층상판 도로교설계기준 Wood Bridge Monitoring Glulam Stress laminated deck Design code of highway bridge 주요 국산 침엽수재의 고부가가치 이용도 증진 저탄소 사회 구축을 위하여 국내 최초로 설계시공된 차량용 목조교량국립미천골휴양림교의 현장성능 모니터링을 통해 교량의 안전성 확보 장기 내구성 분석을 자료 구축 주변 환경 변화에 따른 교량 형상반응 계측 가교량 형상반응 원인 분석을 위해 트러스상현재 아래및 상판가로보 옆개소에서 온습도 변화를 계측함 산간지방에 위치하여 일교차 이에 따른 상대습도의 변화가 컸으며 계곡에 위치한 지리적 특성으로 인해 습도가 대체적으로 높게 나타남 교량 주변의 상대습도는 월월간 월월간 로 변화함에 따라 교량 부재의 성능과 형태의 변화가 있을 수 있음 나교량 받침의 상하 플레이트 간 상대변위 계측을 통해 교축방향 수평변형을 측정함 측정된 수평변형은 mm 내외로 매우 작았으며 교량 받침 신축 이음 부대설비의 안정적인 기능발현을 확인함 다트러스 하현재 가로보개소를 기준으로 하여 지상 LiDar 촬영 사진촬영 수준측량의 방법을 통해 교량의 처짐량인 수직변형을 계측함 수준측량법에 의해 유효한 결과를 도출할 수 있었으며 부재 접합부 손상에 의한 교량의 이상 처짐이 나타나지 않아 전반적으로 양호한 상태를 유지하고 있음을 확인함 라트러스 가로보의 중앙부 처짐량이 년보다 늘어났으나 안정화단계에 이른 것으로 판단되며 한계처짐량보다 매우 작아 구조적으로 안전함을 확인 시간 경과에 따른 트러스 부재 접합부 상태변화 모니터링 가부재 표면에서 발생할 수 있는 할렬 접착층 갈라짐 결함을 육안적으로 확인하였으며 현재까지 전반적으로 양호한 상태를 유지함 나개 트러스와 상하현재 접합부각개소에 대해 부재 사이의 접합부 간격 변화를 계측크랙측정기 적용하고 접합부 다우얼 주위의 갈라짐 발생을 조사함 크랙측정기의 부착성 문제가 있어 보완부재와 볼트연결완료하였으며 현재까지 전반적으로 양호한 상태를 유지함 다트러스 사재의 간격이 넓어지는 현상이 발견되어 구조안전성 검토와 간격의 경시적 분석을 진행하고 있음 시간 경과에 따른 응력적층상판 압체력 변화 모니터링 가응력적층상판의 압체부 개소에 로드셀을 설치하여 압체력 변화를 상시 모니터링 중에 있으며 현재까지 재압체 시점에 도달하지 않음 나환경 변화 반복적인 차량하중 재하에 의해 응력적층상판의 거동변화 해석을 위해 유한요소해석을 수행하였으며 압체력 변화 모니터링 결과와 연계하여 분석 수행 예정임 다트러스 부재에 부후가 진행되는 것으로 의심되는 치마버섯 자실체가 발생하여 정밀진단 중이며 진행되는 부후로 판단되면 방부처리 조치 계획임 라자외선 열화와 빗물피해 예방을 위해 차 도장 배수 공사 실시함 라 기술적 측면 가국산재를 이용하여 생산된 구조부재의 안정적인 구조성능 내구성 확보를 통하여 국산재의 새로운 수요 창출 고부가가치 이용 확대에 기여 나차량용 목조교량 설계기술 검증을 통한 기술력을 확보하고 나아가 국내 도로교설계기준국토해양부 재정에 목조교량의 반영 추진 가TRM 중점분야인 저탄소사회 구축을 목재이용도 증진 중 핵심기술분야로서 재질 정보 목구조시스템 구축 연구를 수행 나연구영역 목구조시스템 연구의 요소기술인 하이브리드 목구조시스템 연구와 관련하여 차량용 목조교량 구조시스템의 구조안정성 내구성 향상에 기여 주변 환경 변화 차량통행량에 따른 교량 형상반응 계측 가공시재료 국립미천골휴양림교교장 m 교폭 m의 차선 등교 나조사항목 교대 받침 수평변형 계측트러스 가로보 수직변형 계측및 방법처리방법 다시험규모 수평변형 개소 + 수직변형 개소시기 라분석항목 계절적인 환경 변화 차량통행량에 따른 목조교량의 수직수평변형 분석 시간 경과에 따른 트러스 부재 접합부 상태변화 모니터링 가공시재료 목조교량 아치 트러스길이 m 높이 m 개 나조사항목 트러스 부재리기다소나무 집성재할렬 표면결함 모니터링트러스 접합부 형상변화 모니터링 다시험규모 트러스부재+접합부시기분기 회 라분석항목 시간 경과에 따른 부재 표면 결함 발생 진행 분석시간 경과에 따른 접합부 간격 형상변화 분석 시간 경과에 따른 응력적층상판 압체력 변화 모니터링 가공시재료 국립미천골휴양림교교장 m 교폭 m의 차선 등교 나조사항목 응력적층상판 압체력 부후 다시험규모 압체부시기분기 회 라분석항목 응력적층상판의 압체력 변화 부후징후 점검\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] 주제 예측 결과 >> result : {'inference': [-1]}\n",
      "INFO:root:[hunmin log] the end line of the function [inference_dataframe]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.17 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inference': [-1]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "inference_dataframe(df, model_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-behavior",
   "metadata": {},
   "source": [
    "### CASE  [File - Dictionary]\n",
    "File 에 대한 추론 결과를 딕셔너리(Dictionary) 형태로 리턴(return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-advance",
   "metadata": {},
   "source": [
    " 1. 아래 Cell을 실행하면 select data 버튼이 생성됩니다.\n",
    " 2. 생성된 select data 버튼을 눌러 추론할 데이터를 선택하세요.\n",
    " 3. 선택 후 **inference_file(files, model_info_dict)** 을 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "initial-witness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6675f0e76b484971be7ec0dc4f889e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='*', button_style='danger', description='select data', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# uploader widget(해당 커널 output의 버튼)에 파일을 업로드 한 뒤 infernece_file으로 추론합니다.\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "alert-bridges",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the start line of the function [exec_inference_file]\n",
      "INFO:root:[hunmin log] the end line of the function [inference_file]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inference': []}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "inference_file(files, model_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-characteristic",
   "metadata": {},
   "source": [
    "### CASE  [File - DownloadFile / DownloadFile의 List]\n",
    "File 입력에 대한 추론 결과를 DownloadFile 형태 혹은 DownloadFile의 List 형태로 리턴(return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "charming-communications",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the start line of the function [exec_inference_file]\n",
      "INFO:root:[hunmin log] the end line of the function [inference_file]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inference': []}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# inference의 return을 DownloadFile 으로 할때 실행합니다.\n",
    "inference_result = inference_file(files, model_info_dict)\n",
    "\n",
    "if type(inference_result) == list:\n",
    "    display(*inference_result)\n",
    "else:\n",
    "    display(inference_result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "image_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "BERTopic_T3Q",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
